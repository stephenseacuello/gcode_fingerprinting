{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18. Transfer Learning\n",
    "\n",
    "Strategies for adapting the model to new machines, operations, or domains.\n",
    "\n",
    "## Contents\n",
    "1. [Setup](#1-setup)\n",
    "2. [Feature Extraction](#2-feature-extraction)\n",
    "3. [Fine-Tuning Strategies](#3-fine-tuning-strategies)\n",
    "4. [Few-Shot Learning](#4-few-shot-learning)\n",
    "5. [Domain Adaptation](#5-domain-adaptation)\n",
    "6. [Multi-Task Transfer](#6-multi-task-transfer)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Optional\n",
    "import json\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "from miracle.model.backbone import MMDTAELSTMBackbone\n",
    "from miracle.model.multihead_lm import MultiHeadGCodeLM\n",
    "\n",
    "VOCAB_PATH = project_root / 'data' / 'gcode_vocab_v2.json'\n",
    "CHECKPOINT_PATH = project_root / 'outputs' / 'final_model' / 'checkpoint_best.pt'\n",
    "\n",
    "with open(VOCAB_PATH) as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device, weights_only=False)\n",
    "    config = checkpoint.get('config', {})\n",
    "else:\n",
    "    config = {'hidden_dim': 256, 'num_layers': 4, 'num_heads': 8, 'dropout': 0.1}\n",
    "\n",
    "# Source model (pretrained)\n",
    "backbone = MMDTAELSTMBackbone(\n",
    "    continuous_dim=155,\n",
    "    categorical_dims=[10, 10, 50, 50],\n",
    "    d_model=config.get('hidden_dim', 256),\n",
    "    num_layers=config.get('num_layers', 4),\n",
    "    num_heads=config.get('num_heads', 8),\n",
    "    dropout=config.get('dropout', 0.1)\n",
    ").to(device)\n",
    "\n",
    "lm = MultiHeadGCodeLM(\n",
    "    d_model=config.get('hidden_dim', 256),\n",
    "    vocab_sizes=vocab.get('head_vocab_sizes', {'type': 10, 'command': 50, 'param_type': 30, 'param_value': 100})\n",
    ").to(device)\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    backbone.load_state_dict(checkpoint['backbone_state_dict'])\n",
    "    lm.load_state_dict(checkpoint['lm_state_dict'])\n",
    "\n",
    "print(\"Pretrained models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic source and target domain data\n",
    "def create_domain_data(n_samples, domain_shift=0.0):\n",
    "    \"\"\"Create synthetic domain data with optional shift.\"\"\"\n",
    "    continuous = torch.randn(n_samples, 64, 155)\n",
    "    # Apply domain-specific transformation\n",
    "    if domain_shift > 0:\n",
    "        continuous = continuous * (1 + domain_shift) + domain_shift * torch.randn_like(continuous)\n",
    "    categorical = torch.randint(0, 10, (n_samples, 64, 4))\n",
    "    return continuous, categorical\n",
    "\n",
    "# Source domain (original)\n",
    "source_cont, source_cat = create_domain_data(100, domain_shift=0.0)\n",
    "\n",
    "# Target domain (shifted)\n",
    "target_cont, target_cat = create_domain_data(20, domain_shift=0.3)\n",
    "\n",
    "print(f\"Source domain: {source_cont.shape}\")\n",
    "print(f\"Target domain: {target_cont.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction\n",
    "\n",
    "Use pretrained backbone as fixed feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"Use pretrained backbone for feature extraction.\"\"\"\n",
    "    \n",
    "    def __init__(self, backbone, freeze=True):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        \n",
    "        if freeze:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    def forward(self, continuous, categorical):\n",
    "        return self.backbone(continuous, categorical)\n",
    "    \n",
    "    def extract_features(self, continuous, categorical, layer=-1):\n",
    "        \"\"\"Extract features from specific layer.\"\"\"\n",
    "        # Get hidden states\n",
    "        hidden = self.backbone(continuous, categorical)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "class TransferHead(nn.Module):\n",
    "    \"\"\"New classification head for target domain.\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(d_model // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        return self.classifier(features)\n",
    "\n",
    "\n",
    "# Create feature extractor\n",
    "feature_extractor = FeatureExtractor(backbone, freeze=True)\n",
    "new_head = TransferHead(config.get('hidden_dim', 256), num_classes=20).to(device)\n",
    "\n",
    "# Extract features\n",
    "with torch.no_grad():\n",
    "    source_features = feature_extractor(source_cont[:10].to(device), source_cat[:10].to(device))\n",
    "    target_features = feature_extractor(target_cont[:10].to(device), target_cat[:10].to(device))\n",
    "\n",
    "print(f\"Source features: {source_features.shape}\")\n",
    "print(f\"Target features: {target_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Flatten features for PCA\n",
    "source_flat = source_features.view(-1, source_features.shape[-1]).cpu().numpy()\n",
    "target_flat = target_features.view(-1, target_features.shape[-1]).cpu().numpy()\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "combined = np.vstack([source_flat[:500], target_flat[:500]])\n",
    "combined_pca = pca.fit_transform(combined)\n",
    "\n",
    "source_pca = combined_pca[:500]\n",
    "target_pca = combined_pca[500:]\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(source_pca[:, 0], source_pca[:, 1], alpha=0.5, label='Source Domain', s=10)\n",
    "ax.scatter(target_pca[:, 0], target_pca[:, 1], alpha=0.5, label='Target Domain', s=10)\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_title('Feature Space: Source vs Target Domain')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'reports' / 'domain_features.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fine-Tuning Strategies\n",
    "\n",
    "Different approaches to fine-tuning pretrained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerWiseLR:\n",
    "    \"\"\"Assign different learning rates to different layers.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_param_groups(model, base_lr, decay_factor=0.9):\n",
    "        \"\"\"Create parameter groups with layer-wise LR decay.\"\"\"\n",
    "        param_groups = []\n",
    "        \n",
    "        # Get all named parameters\n",
    "        named_params = list(model.named_parameters())\n",
    "        n_layers = len(named_params)\n",
    "        \n",
    "        for i, (name, param) in enumerate(named_params):\n",
    "            # Earlier layers get smaller LR\n",
    "            layer_lr = base_lr * (decay_factor ** (n_layers - i - 1))\n",
    "            param_groups.append({\n",
    "                'params': [param],\n",
    "                'lr': layer_lr,\n",
    "                'name': name\n",
    "            })\n",
    "        \n",
    "        return param_groups\n",
    "\n",
    "\n",
    "class GradualUnfreezing:\n",
    "    \"\"\"Gradually unfreeze layers during training.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, unfreeze_schedule):\n",
    "        self.model = model\n",
    "        self.schedule = unfreeze_schedule\n",
    "        self.current_epoch = 0\n",
    "        \n",
    "        # Initially freeze all\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def step(self, epoch):\n",
    "        \"\"\"Unfreeze layers according to schedule.\"\"\"\n",
    "        self.current_epoch = epoch\n",
    "        \n",
    "        named_params = list(self.model.named_parameters())\n",
    "        n_layers = len(named_params)\n",
    "        \n",
    "        # Calculate how many layers to unfreeze\n",
    "        for unfreeze_epoch, n_unfreeze in self.schedule.items():\n",
    "            if epoch >= int(unfreeze_epoch):\n",
    "                # Unfreeze last n_unfreeze layers\n",
    "                for name, param in named_params[-n_unfreeze:]:\n",
    "                    param.requires_grad = True\n",
    "\n",
    "\n",
    "class DiscriminativeFineTuning:\n",
    "    \"\"\"Fine-tuning with discriminative learning rates.\"\"\"\n",
    "    \n",
    "    def __init__(self, backbone, lm, base_lr=1e-4, ratio=2.6):\n",
    "        self.backbone = backbone\n",
    "        self.lm = lm\n",
    "        self.base_lr = base_lr\n",
    "        self.ratio = ratio\n",
    "    \n",
    "    def get_optimizer(self):\n",
    "        \"\"\"Create optimizer with discriminative LRs.\"\"\"\n",
    "        # Backbone gets smaller LR\n",
    "        backbone_params = list(self.backbone.parameters())\n",
    "        lm_params = list(self.lm.parameters())\n",
    "        \n",
    "        n_backbone = len(backbone_params)\n",
    "        \n",
    "        param_groups = []\n",
    "        \n",
    "        # Backbone layers with decreasing LR\n",
    "        for i, param in enumerate(backbone_params):\n",
    "            lr = self.base_lr / (self.ratio ** (n_backbone - i))\n",
    "            param_groups.append({'params': [param], 'lr': lr})\n",
    "        \n",
    "        # LM head with base LR\n",
    "        param_groups.append({'params': lm_params, 'lr': self.base_lr})\n",
    "        \n",
    "        return torch.optim.AdamW(param_groups)\n",
    "\n",
    "\n",
    "# Demonstrate fine-tuning setup\n",
    "fine_tuner = DiscriminativeFineTuning(backbone, lm, base_lr=1e-4)\n",
    "optimizer = fine_tuner.get_optimizer()\n",
    "\n",
    "print(f\"Number of parameter groups: {len(optimizer.param_groups)}\")\n",
    "print(f\"LR range: {optimizer.param_groups[0]['lr']:.2e} to {optimizer.param_groups[-1]['lr']:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Few-Shot Learning\n",
    "\n",
    "Learn from limited target domain examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalNetwork:\n",
    "    \"\"\"Few-shot learning using prototypes.\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_extractor):\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.prototypes = {}\n",
    "    \n",
    "    def compute_prototypes(self, support_data, support_labels):\n",
    "        \"\"\"Compute class prototypes from support set.\"\"\"\n",
    "        continuous, categorical = support_data\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = self.feature_extractor(continuous, categorical)\n",
    "        \n",
    "        # Pool features per sample\n",
    "        pooled = features.mean(dim=1)  # [N, d_model]\n",
    "        \n",
    "        # Compute prototype per class\n",
    "        unique_labels = torch.unique(support_labels)\n",
    "        for label in unique_labels:\n",
    "            mask = support_labels == label\n",
    "            self.prototypes[label.item()] = pooled[mask].mean(dim=0)\n",
    "        \n",
    "        return self.prototypes\n",
    "    \n",
    "    def predict(self, query_data):\n",
    "        \"\"\"Predict by finding nearest prototype.\"\"\"\n",
    "        continuous, categorical = query_data\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = self.feature_extractor(continuous, categorical)\n",
    "        \n",
    "        pooled = features.mean(dim=1)  # [N, d_model]\n",
    "        \n",
    "        # Compute distances to prototypes\n",
    "        distances = {}\n",
    "        for label, proto in self.prototypes.items():\n",
    "            dist = torch.cdist(pooled, proto.unsqueeze(0))\n",
    "            distances[label] = dist.squeeze(-1)\n",
    "        \n",
    "        # Stack and find minimum\n",
    "        labels = list(distances.keys())\n",
    "        dist_matrix = torch.stack([distances[l] for l in labels], dim=1)\n",
    "        pred_indices = dist_matrix.argmin(dim=1)\n",
    "        predictions = torch.tensor([labels[i] for i in pred_indices])\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Demo few-shot learning\n",
    "proto_net = PrototypicalNetwork(feature_extractor)\n",
    "\n",
    "# Create synthetic support set (5-shot, 4-way)\n",
    "n_way = 4\n",
    "n_shot = 5\n",
    "\n",
    "support_cont = target_cont[:n_way * n_shot].to(device)\n",
    "support_cat = target_cat[:n_way * n_shot].to(device)\n",
    "support_labels = torch.tensor([i // n_shot for i in range(n_way * n_shot)])\n",
    "\n",
    "# Compute prototypes\n",
    "prototypes = proto_net.compute_prototypes(\n",
    "    (support_cont, support_cat), \n",
    "    support_labels\n",
    ")\n",
    "\n",
    "print(f\"Computed {len(prototypes)} prototypes\")\n",
    "print(f\"Prototype shape: {list(prototypes.values())[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prototypes\n",
    "proto_features = torch.stack(list(prototypes.values())).cpu().numpy()\n",
    "\n",
    "# PCA on prototypes\n",
    "pca = PCA(n_components=2)\n",
    "proto_pca = pca.fit_transform(proto_features)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "for i, (label, coords) in enumerate(zip(prototypes.keys(), proto_pca)):\n",
    "    ax.scatter(coords[0], coords[1], s=200, marker='*', label=f'Class {label}')\n",
    "    ax.annotate(f'Class {label}', (coords[0], coords[1]), textcoords='offset points', xytext=(5, 5))\n",
    "\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_title('Class Prototypes in Feature Space')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'reports' / 'few_shot_prototypes.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Domain Adaptation\n",
    "\n",
    "Adapt to target domain without labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainAdversarialNetwork(nn.Module):\n",
    "    \"\"\"Domain Adversarial Neural Network (DANN) for adaptation.\"\"\"\n",
    "    \n",
    "    def __init__(self, backbone, d_model):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        \n",
    "        # Domain classifier\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(d_model // 2, 2)  # Source vs Target\n",
    "        )\n",
    "    \n",
    "    def forward(self, continuous, categorical, alpha=1.0):\n",
    "        features = self.backbone(continuous, categorical)\n",
    "        \n",
    "        # Global average pooling\n",
    "        pooled = features.mean(dim=1)\n",
    "        \n",
    "        # Gradient reversal for domain classifier\n",
    "        reversed_features = GradientReversal.apply(pooled, alpha)\n",
    "        domain_output = self.domain_classifier(reversed_features)\n",
    "        \n",
    "        return features, domain_output\n",
    "\n",
    "\n",
    "class GradientReversal(torch.autograd.Function):\n",
    "    \"\"\"Gradient reversal layer.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return -ctx.alpha * grad_output, None\n",
    "\n",
    "\n",
    "class MMDLoss(nn.Module):\n",
    "    \"\"\"Maximum Mean Discrepancy loss for domain adaptation.\"\"\"\n",
    "    \n",
    "    def __init__(self, kernel='rbf', sigma=1.0):\n",
    "        super().__init__()\n",
    "        self.kernel = kernel\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def gaussian_kernel(self, x, y):\n",
    "        \"\"\"Compute Gaussian kernel.\"\"\"\n",
    "        xx = torch.cdist(x, x)\n",
    "        yy = torch.cdist(y, y)\n",
    "        xy = torch.cdist(x, y)\n",
    "        \n",
    "        k_xx = torch.exp(-xx ** 2 / (2 * self.sigma ** 2))\n",
    "        k_yy = torch.exp(-yy ** 2 / (2 * self.sigma ** 2))\n",
    "        k_xy = torch.exp(-xy ** 2 / (2 * self.sigma ** 2))\n",
    "        \n",
    "        return k_xx, k_yy, k_xy\n",
    "    \n",
    "    def forward(self, source_features, target_features):\n",
    "        \"\"\"Compute MMD loss.\"\"\"\n",
    "        k_xx, k_yy, k_xy = self.gaussian_kernel(source_features, target_features)\n",
    "        \n",
    "        m = source_features.size(0)\n",
    "        n = target_features.size(0)\n",
    "        \n",
    "        mmd = (k_xx.sum() / (m * m) + \n",
    "               k_yy.sum() / (n * n) - \n",
    "               2 * k_xy.sum() / (m * n))\n",
    "        \n",
    "        return mmd\n",
    "\n",
    "\n",
    "# Compute MMD between domains\n",
    "mmd_loss = MMDLoss(sigma=1.0)\n",
    "\n",
    "source_pooled = source_features.mean(dim=1)\n",
    "target_pooled = target_features.mean(dim=1)\n",
    "\n",
    "mmd = mmd_loss(source_pooled, target_pooled)\n",
    "print(f\"MMD between source and target: {mmd.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-Task Transfer\n",
    "\n",
    "Transfer knowledge across related tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskTransfer(nn.Module):\n",
    "    \"\"\"Multi-task learning with shared backbone.\"\"\"\n",
    "    \n",
    "    def __init__(self, backbone, d_model, task_configs):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        \n",
    "        # Task-specific heads\n",
    "        self.task_heads = nn.ModuleDict({\n",
    "            name: nn.Sequential(\n",
    "                nn.Linear(d_model, d_model // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(d_model // 2, n_classes)\n",
    "            )\n",
    "            for name, n_classes in task_configs.items()\n",
    "        })\n",
    "        \n",
    "        # Task-specific adapters\n",
    "        self.adapters = nn.ModuleDict({\n",
    "            name: nn.Sequential(\n",
    "                nn.Linear(d_model, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, d_model)\n",
    "            )\n",
    "            for name in task_configs.keys()\n",
    "        })\n",
    "    \n",
    "    def forward(self, continuous, categorical, task_name):\n",
    "        # Shared features\n",
    "        features = self.backbone(continuous, categorical)\n",
    "        \n",
    "        # Task-specific adaptation\n",
    "        adapted = features + self.adapters[task_name](features)\n",
    "        \n",
    "        # Task-specific prediction\n",
    "        return self.task_heads[task_name](adapted)\n",
    "\n",
    "\n",
    "class AdapterModule(nn.Module):\n",
    "    \"\"\"Lightweight adapter for efficient transfer.\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, bottleneck_dim=64):\n",
    "        super().__init__()\n",
    "        self.down_proj = nn.Linear(d_model, bottleneck_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.up_proj = nn.Linear(bottleneck_dim, d_model)\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.scale * self.up_proj(self.activation(self.down_proj(x)))\n",
    "\n",
    "\n",
    "# Demo multi-task setup\n",
    "task_configs = {\n",
    "    'machine_id': 5,      # Identify machine\n",
    "    'operation_type': 10, # Classify operation\n",
    "    'anomaly': 2,         # Binary anomaly detection\n",
    "}\n",
    "\n",
    "multi_task = MultiTaskTransfer(backbone, config.get('hidden_dim', 256), task_configs).to(device)\n",
    "\n",
    "# Forward pass for each task\n",
    "with torch.no_grad():\n",
    "    for task in task_configs.keys():\n",
    "        output = multi_task(target_cont[:5].to(device), target_cat[:5].to(device), task)\n",
    "        print(f\"{task}: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize transfer learning configurations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Strategy comparison\n",
    "strategies = ['Feature\\nExtraction', 'Full\\nFine-tuning', 'Gradual\\nUnfreezing', 'Discriminative\\nLR']\n",
    "expected_perf = [0.7, 0.85, 0.88, 0.9]\n",
    "training_cost = [0.1, 1.0, 0.6, 0.8]\n",
    "\n",
    "x = np.arange(len(strategies))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 0].bar(x - width/2, expected_perf, width, label='Expected Accuracy', color='steelblue')\n",
    "axes[0, 0].bar(x + width/2, training_cost, width, label='Training Cost', color='coral')\n",
    "axes[0, 0].set_ylabel('Score')\n",
    "axes[0, 0].set_title('Fine-tuning Strategy Comparison')\n",
    "axes[0, 0].set_xticks(x)\n",
    "axes[0, 0].set_xticklabels(strategies)\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Few-shot performance\n",
    "shots = [1, 2, 5, 10, 20]\n",
    "perf = [0.4, 0.55, 0.72, 0.82, 0.88]\n",
    "axes[0, 1].plot(shots, perf, 'o-', linewidth=2, markersize=8)\n",
    "axes[0, 1].set_xlabel('Number of Shots (K)')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].set_title('Few-Shot Learning Performance')\n",
    "axes[0, 1].set_xscale('log')\n",
    "\n",
    "# Domain adaptation effect\n",
    "epochs = list(range(1, 21))\n",
    "source_acc = [0.9] * 20\n",
    "target_before = [0.5 + 0.01 * e for e in epochs]\n",
    "target_after = [0.5 + 0.02 * e for e in epochs]\n",
    "\n",
    "axes[1, 0].plot(epochs, source_acc, 'b-', label='Source Domain')\n",
    "axes[1, 0].plot(epochs, target_before, 'r--', label='Target (no adaptation)')\n",
    "axes[1, 0].plot(epochs, target_after, 'g-', label='Target (with DANN)')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].set_title('Domain Adaptation Effect')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Multi-task benefits\n",
    "tasks = ['Machine\\nID', 'Operation\\nType', 'Anomaly']\n",
    "single_task = [0.75, 0.80, 0.70]\n",
    "multi_task_perf = [0.82, 0.85, 0.78]\n",
    "\n",
    "x = np.arange(len(tasks))\n",
    "axes[1, 1].bar(x - width/2, single_task, width, label='Single-task', color='coral')\n",
    "axes[1, 1].bar(x + width/2, multi_task_perf, width, label='Multi-task', color='forestgreen')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].set_title('Multi-Task Transfer Benefits')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(tasks)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'reports' / 'transfer_learning_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook covers transfer learning strategies:\n",
    "\n",
    "1. **Feature Extraction**: Use frozen backbone as feature extractor\n",
    "2. **Fine-Tuning**: Discriminative LR, gradual unfreezing\n",
    "3. **Few-Shot**: Prototypical networks for limited data\n",
    "4. **Domain Adaptation**: DANN, MMD for unsupervised adaptation\n",
    "5. **Multi-Task**: Shared backbone with task-specific adapters\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation:**\n",
    "← [Previous: 17_uncertainty_quantification](17_uncertainty_quantification.ipynb) |\n",
    "[Next: 19_streaming_inference](19_streaming_inference.ipynb) →"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
