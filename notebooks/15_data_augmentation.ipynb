{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Data Augmentation\n",
    "\n",
    "Data augmentation strategies for improving model generalization on sensor time series.\n",
    "\n",
    "## Contents\n",
    "1. [Setup](#1-setup)\n",
    "2. [Time-Domain Augmentations](#2-time-domain-augmentations)\n",
    "3. [Magnitude Augmentations](#3-magnitude-augmentations)\n",
    "4. [Mixup and CutMix](#4-mixup-and-cutmix)\n",
    "5. [Sensor-Specific Augmentations](#5-sensor-specific-augmentations)\n",
    "6. [Augmentation Pipeline](#6-augmentation-pipeline)\n",
    "7. [Evaluation with Augmentation](#7-evaluation-with-augmentation)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import interpolate, signal\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "\n",
    "# Environment check\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data for visualization\n",
    "DATA_DIR = project_root / 'outputs' / 'processed_v2'\n",
    "test_path = DATA_DIR / 'test.pt'\n",
    "\n",
    "if test_path.exists():\n",
    "    test_data = torch.load(test_path, weights_only=False)\n",
    "    sample_continuous = torch.tensor(test_data['continuous'][:10], dtype=torch.float32)\n",
    "    sample_categorical = torch.tensor(test_data['categorical'][:10], dtype=torch.long)\n",
    "    print(f\"Sample data: {sample_continuous.shape}\")\n",
    "else:\n",
    "    # Generate synthetic sample\n",
    "    print(\"Using synthetic sample data\")\n",
    "    sample_continuous = torch.randn(10, 64, 155)\n",
    "    sample_categorical = torch.randint(0, 10, (10, 64, 4))\n",
    "\n",
    "# Single sample for visualization\n",
    "vis_sample = sample_continuous[0].clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time-Domain Augmentations\n",
    "\n",
    "Augmentations that modify the temporal structure of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeWarping:\n",
    "    \"\"\"Non-linear time warping augmentation.\"\"\"\n",
    "    \n",
    "    def __init__(self, sigma=0.2, knot_density=4):\n",
    "        self.sigma = sigma\n",
    "        self.knot_density = knot_density\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Apply time warping.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape [T, C] or [B, T, C]\n",
    "        \"\"\"\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "            squeeze = True\n",
    "        else:\n",
    "            squeeze = False\n",
    "            \n",
    "        B, T, C = x.shape\n",
    "        \n",
    "        # Create warping curve using random knots\n",
    "        num_knots = max(2, T // self.knot_density)\n",
    "        knot_positions = np.linspace(0, T - 1, num_knots)\n",
    "        \n",
    "        warped_batch = []\n",
    "        for b in range(B):\n",
    "            # Random warping at knot positions\n",
    "            warp_values = knot_positions + np.random.randn(num_knots) * self.sigma * T / num_knots\n",
    "            warp_values = np.clip(warp_values, 0, T - 1)\n",
    "            warp_values = np.sort(warp_values)  # Ensure monotonicity\n",
    "            \n",
    "            # Interpolate to get full warping function\n",
    "            warp_fn = interpolate.interp1d(knot_positions, warp_values, kind='cubic', fill_value='extrapolate')\n",
    "            warped_indices = warp_fn(np.arange(T))\n",
    "            warped_indices = np.clip(warped_indices, 0, T - 1)\n",
    "            \n",
    "            # Apply warping by interpolation\n",
    "            x_np = x[b].numpy()\n",
    "            warped = np.zeros_like(x_np)\n",
    "            for c in range(C):\n",
    "                interp_fn = interpolate.interp1d(np.arange(T), x_np[:, c], kind='linear', fill_value='extrapolate')\n",
    "                warped[:, c] = interp_fn(warped_indices)\n",
    "            \n",
    "            warped_batch.append(torch.tensor(warped, dtype=x.dtype))\n",
    "        \n",
    "        result = torch.stack(warped_batch)\n",
    "        return result.squeeze(0) if squeeze else result\n",
    "\n",
    "# Test time warping\n",
    "time_warp = TimeWarping(sigma=0.1)\n",
    "warped_sample = time_warp(vis_sample)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "channel = 0\n",
    "axes[0].plot(vis_sample[:, channel].numpy(), label='Original', alpha=0.8)\n",
    "axes[0].plot(warped_sample[:, channel].numpy(), label='Time Warped', alpha=0.8)\n",
    "axes[0].set_xlabel('Time Step')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].set_title('Time Warping Effect (Channel 0)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Show warping on multiple channels\n",
    "for c in range(5):\n",
    "    offset = c * 2\n",
    "    axes[1].plot(vis_sample[:, c].numpy() + offset, 'b-', alpha=0.5)\n",
    "    axes[1].plot(warped_sample[:, c].numpy() + offset, 'r-', alpha=0.5)\n",
    "axes[1].set_xlabel('Time Step')\n",
    "axes[1].set_title('Time Warping: Original (blue) vs Warped (red)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowSlicing:\n",
    "    \"\"\"Extract random time windows with optional resampling.\"\"\"\n",
    "    \n",
    "    def __init__(self, crop_ratio=0.9, resample=True):\n",
    "        self.crop_ratio = crop_ratio\n",
    "        self.resample = resample\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "            squeeze = True\n",
    "        else:\n",
    "            squeeze = False\n",
    "            \n",
    "        B, T, C = x.shape\n",
    "        crop_len = int(T * self.crop_ratio)\n",
    "        \n",
    "        result = []\n",
    "        for b in range(B):\n",
    "            start = random.randint(0, T - crop_len)\n",
    "            cropped = x[b, start:start + crop_len, :]\n",
    "            \n",
    "            if self.resample:\n",
    "                # Resample back to original length\n",
    "                cropped_np = cropped.numpy()\n",
    "                resampled = signal.resample(cropped_np, T, axis=0)\n",
    "                result.append(torch.tensor(resampled, dtype=x.dtype))\n",
    "            else:\n",
    "                # Pad to original length\n",
    "                padded = F.pad(cropped.T, (0, T - crop_len)).T\n",
    "                result.append(padded)\n",
    "        \n",
    "        output = torch.stack(result)\n",
    "        return output.squeeze(0) if squeeze else output\n",
    "\n",
    "\n",
    "class RandomCrop:\n",
    "    \"\"\"Random cropping with reflection padding.\"\"\"\n",
    "    \n",
    "    def __init__(self, crop_fraction=0.1):\n",
    "        self.crop_fraction = crop_fraction\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        T = x.shape[-2]\n",
    "        crop_amount = int(T * self.crop_fraction)\n",
    "        \n",
    "        start_crop = random.randint(0, crop_amount)\n",
    "        end_crop = random.randint(0, crop_amount)\n",
    "        \n",
    "        cropped = x[..., start_crop:T-end_crop, :]\n",
    "        \n",
    "        # Pad back with reflection\n",
    "        if cropped.dim() == 2:\n",
    "            cropped = cropped.unsqueeze(0)\n",
    "            padded = F.pad(cropped.permute(0, 2, 1), (start_crop, end_crop), mode='reflect').permute(0, 2, 1)\n",
    "            return padded.squeeze(0)\n",
    "        else:\n",
    "            padded = F.pad(cropped.permute(0, 2, 1), (start_crop, end_crop), mode='reflect').permute(0, 2, 1)\n",
    "            return padded\n",
    "\n",
    "\n",
    "class TimeShift:\n",
    "    \"\"\"Circular shift in time.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_shift_ratio=0.1):\n",
    "        self.max_shift_ratio = max_shift_ratio\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        T = x.shape[-2]\n",
    "        max_shift = int(T * self.max_shift_ratio)\n",
    "        shift = random.randint(-max_shift, max_shift)\n",
    "        return torch.roll(x, shifts=shift, dims=-2)\n",
    "\n",
    "\n",
    "# Test and visualize\n",
    "augmentations = {\n",
    "    'Window Slicing': WindowSlicing(crop_ratio=0.8),\n",
    "    'Random Crop': RandomCrop(crop_fraction=0.15),\n",
    "    'Time Shift': TimeShift(max_shift_ratio=0.1),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "channel = 0\n",
    "axes[0, 0].plot(vis_sample[:, channel].numpy())\n",
    "axes[0, 0].set_title('Original')\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "\n",
    "for ax, (name, aug) in zip(axes.flat[1:], augmentations.items()):\n",
    "    augmented = aug(vis_sample)\n",
    "    ax.plot(augmented[:, channel].numpy())\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel('Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'reports' / 'time_augmentations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Magnitude Augmentations\n",
    "\n",
    "Augmentations that modify signal amplitude and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise:\n",
    "    \"\"\"Add Gaussian noise.\"\"\"\n",
    "    \n",
    "    def __init__(self, std=0.1):\n",
    "        self.std = std\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        noise = torch.randn_like(x) * self.std\n",
    "        return x + noise\n",
    "\n",
    "\n",
    "class Scaling:\n",
    "    \"\"\"Random scaling of magnitude.\"\"\"\n",
    "    \n",
    "    def __init__(self, sigma=0.1):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Random scale factor per channel\n",
    "        scale = 1 + torch.randn(x.shape[-1]) * self.sigma\n",
    "        return x * scale\n",
    "\n",
    "\n",
    "class MagnitudeWarping:\n",
    "    \"\"\"Smooth, random magnitude warping.\"\"\"\n",
    "    \n",
    "    def __init__(self, sigma=0.2, knot_density=4):\n",
    "        self.sigma = sigma\n",
    "        self.knot_density = knot_density\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.dim() == 2:\n",
    "            T, C = x.shape\n",
    "            squeeze = True\n",
    "            x = x.unsqueeze(0)\n",
    "        else:\n",
    "            B, T, C = x.shape\n",
    "            squeeze = False\n",
    "        \n",
    "        B = x.shape[0]\n",
    "        num_knots = max(2, T // self.knot_density)\n",
    "        \n",
    "        result = []\n",
    "        for b in range(B):\n",
    "            knot_positions = np.linspace(0, T - 1, num_knots)\n",
    "            warp_values = 1 + np.random.randn(num_knots) * self.sigma\n",
    "            \n",
    "            warp_fn = interpolate.interp1d(knot_positions, warp_values, kind='cubic', fill_value='extrapolate')\n",
    "            warp_curve = torch.tensor(warp_fn(np.arange(T)), dtype=x.dtype).unsqueeze(-1)\n",
    "            \n",
    "            result.append(x[b] * warp_curve)\n",
    "        \n",
    "        output = torch.stack(result)\n",
    "        return output.squeeze(0) if squeeze else output\n",
    "\n",
    "\n",
    "class ChannelDropout:\n",
    "    \"\"\"Randomly drop sensor channels.\"\"\"\n",
    "    \n",
    "    def __init__(self, p=0.1):\n",
    "        self.p = p\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        mask = torch.rand(x.shape[-1]) > self.p\n",
    "        return x * mask.float()\n",
    "\n",
    "\n",
    "class ChannelShuffle:\n",
    "    \"\"\"Shuffle a subset of channels.\"\"\"\n",
    "    \n",
    "    def __init__(self, shuffle_ratio=0.1):\n",
    "        self.shuffle_ratio = shuffle_ratio\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        C = x.shape[-1]\n",
    "        num_shuffle = int(C * self.shuffle_ratio)\n",
    "        \n",
    "        if num_shuffle < 2:\n",
    "            return x\n",
    "        \n",
    "        # Select channels to shuffle\n",
    "        indices = torch.randperm(C)[:num_shuffle]\n",
    "        shuffle_order = indices[torch.randperm(num_shuffle)]\n",
    "        \n",
    "        result = x.clone()\n",
    "        result[..., indices] = x[..., shuffle_order]\n",
    "        return result\n",
    "\n",
    "\n",
    "# Visualize magnitude augmentations\n",
    "mag_augmentations = {\n",
    "    'Gaussian Noise': GaussianNoise(std=0.2),\n",
    "    'Scaling': Scaling(sigma=0.2),\n",
    "    'Magnitude Warp': MagnitudeWarping(sigma=0.2),\n",
    "    'Channel Dropout': ChannelDropout(p=0.3),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "channel = 0\n",
    "axes[0, 0].plot(vis_sample[:, channel].numpy())\n",
    "axes[0, 0].set_title('Original')\n",
    "\n",
    "for ax, (name, aug) in zip(axes.flat[1:5], mag_augmentations.items()):\n",
    "    augmented = aug(vis_sample.clone())\n",
    "    ax.plot(augmented[:, channel].numpy())\n",
    "    ax.set_title(name)\n",
    "\n",
    "# Remove empty subplot\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'reports' / 'magnitude_augmentations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mixup and CutMix\n",
    "\n",
    "Advanced mixing strategies for regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixup:\n",
    "    \"\"\"Mixup augmentation for time series.\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=0.4):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def __call__(self, x1: torch.Tensor, x2: torch.Tensor, \n",
    "                 y1: Optional[torch.Tensor] = None, y2: Optional[torch.Tensor] = None\n",
    "                ) -> Tuple[torch.Tensor, Optional[torch.Tensor], float]:\n",
    "        \"\"\"Mix two samples.\n",
    "        \n",
    "        Returns:\n",
    "            mixed_x, mixed_y (if targets provided), lambda value\n",
    "        \"\"\"\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        mixed_x = lam * x1 + (1 - lam) * x2\n",
    "        \n",
    "        if y1 is not None and y2 is not None:\n",
    "            mixed_y = lam * y1 + (1 - lam) * y2\n",
    "            return mixed_x, mixed_y, lam\n",
    "        \n",
    "        return mixed_x, None, lam\n",
    "\n",
    "\n",
    "class CutMix:\n",
    "    \"\"\"CutMix: Cut and paste between samples.\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def __call__(self, x1: torch.Tensor, x2: torch.Tensor,\n",
    "                 y1: Optional[torch.Tensor] = None, y2: Optional[torch.Tensor] = None\n",
    "                ) -> Tuple[torch.Tensor, Optional[torch.Tensor], float]:\n",
    "        \"\"\"Cut and mix two samples along time dimension.\"\"\"\n",
    "        T = x1.shape[-2]\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        \n",
    "        cut_len = int(T * (1 - lam))\n",
    "        cut_start = random.randint(0, T - cut_len)\n",
    "        \n",
    "        mixed = x1.clone()\n",
    "        mixed[..., cut_start:cut_start + cut_len, :] = x2[..., cut_start:cut_start + cut_len, :]\n",
    "        \n",
    "        # Actual lambda after cutting\n",
    "        actual_lam = 1 - cut_len / T\n",
    "        \n",
    "        if y1 is not None and y2 is not None:\n",
    "            mixed_y = actual_lam * y1 + (1 - actual_lam) * y2\n",
    "            return mixed, mixed_y, actual_lam\n",
    "        \n",
    "        return mixed, None, actual_lam\n",
    "\n",
    "\n",
    "class TemporalCutMix:\n",
    "    \"\"\"CutMix with multiple random temporal segments.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_segments=3, alpha=1.0):\n",
    "        self.num_segments = num_segments\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def __call__(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "        T = x1.shape[-2]\n",
    "        mixed = x1.clone()\n",
    "        \n",
    "        for _ in range(self.num_segments):\n",
    "            if random.random() < 0.5:\n",
    "                seg_len = random.randint(1, T // (self.num_segments * 2))\n",
    "                start = random.randint(0, T - seg_len)\n",
    "                mixed[..., start:start + seg_len, :] = x2[..., start:start + seg_len, :]\n",
    "        \n",
    "        return mixed\n",
    "\n",
    "\n",
    "# Visualize mixing strategies\n",
    "sample1 = sample_continuous[0]\n",
    "sample2 = sample_continuous[1]\n",
    "\n",
    "mixup = Mixup(alpha=0.4)\n",
    "cutmix = CutMix(alpha=1.0)\n",
    "temporal_cutmix = TemporalCutMix(num_segments=3)\n",
    "\n",
    "mixed_mixup, _, lam1 = mixup(sample1, sample2)\n",
    "mixed_cutmix, _, lam2 = cutmix(sample1, sample2)\n",
    "mixed_temporal = temporal_cutmix(sample1, sample2)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "channel = 0\n",
    "axes[0, 0].plot(sample1[:, channel].numpy(), label='Sample 1')\n",
    "axes[0, 0].plot(sample2[:, channel].numpy(), label='Sample 2', alpha=0.7)\n",
    "axes[0, 0].set_title('Original Samples')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "axes[0, 1].plot(mixed_mixup[:, channel].numpy())\n",
    "axes[0, 1].set_title(f'Mixup (λ={lam1:.2f})')\n",
    "\n",
    "axes[0, 2].plot(mixed_cutmix[:, channel].numpy())\n",
    "axes[0, 2].set_title(f'CutMix (λ={lam2:.2f})')\n",
    "\n",
    "axes[1, 0].plot(mixed_temporal[:, channel].numpy())\n",
    "axes[1, 0].set_title('Temporal CutMix')\n",
    "\n",
    "# Show difference\n",
    "axes[1, 1].fill_between(range(len(sample1)), \n",
    "                        (mixed_cutmix[:, channel] - sample1[:, channel]).numpy(),\n",
    "                        alpha=0.5, label='Difference')\n",
    "axes[1, 1].set_title('CutMix Difference from Sample 1')\n",
    "axes[1, 1].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'reports' / 'mixing_augmentations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sensor-Specific Augmentations\n",
    "\n",
    "Augmentations designed for CNC sensor data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorGroupMask:\n",
    "    \"\"\"Mask entire sensor groups to simulate sensor failures.\"\"\"\n",
    "    \n",
    "    def __init__(self, sensor_groups: Dict[str, slice], mask_prob=0.1):\n",
    "        self.sensor_groups = sensor_groups\n",
    "        self.mask_prob = mask_prob\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result = x.clone()\n",
    "        for group_name, group_slice in self.sensor_groups.items():\n",
    "            if random.random() < self.mask_prob:\n",
    "                result[..., group_slice] = 0\n",
    "        return result\n",
    "\n",
    "\n",
    "class AxisPermutation:\n",
    "    \"\"\"Randomly permute sensor axes (e.g., swap X, Y, Z).\"\"\"\n",
    "    \n",
    "    def __init__(self, axis_groups: List[List[int]], permute_prob=0.5):\n",
    "        self.axis_groups = axis_groups\n",
    "        self.permute_prob = permute_prob\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result = x.clone()\n",
    "        \n",
    "        for group in self.axis_groups:\n",
    "            if random.random() < self.permute_prob:\n",
    "                perm = torch.randperm(len(group))\n",
    "                permuted_indices = [group[p] for p in perm]\n",
    "                result[..., group] = x[..., permuted_indices]\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "class MotionProfilePerturbation:\n",
    "    \"\"\"Perturb motion profiles while maintaining physical plausibility.\"\"\"\n",
    "    \n",
    "    def __init__(self, velocity_noise=0.05, acceleration_jitter=0.1):\n",
    "        self.velocity_noise = velocity_noise\n",
    "        self.acceleration_jitter = acceleration_jitter\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor, velocity_channels: slice = slice(30, 60),\n",
    "                 accel_channels: slice = slice(60, 90)) -> torch.Tensor:\n",
    "        result = x.clone()\n",
    "        \n",
    "        # Add noise to velocity\n",
    "        vel_noise = torch.randn_like(result[..., velocity_channels]) * self.velocity_noise\n",
    "        result[..., velocity_channels] += vel_noise\n",
    "        \n",
    "        # Add jitter to acceleration\n",
    "        accel_jitter = torch.randn_like(result[..., accel_channels]) * self.acceleration_jitter\n",
    "        result[..., accel_channels] += accel_jitter\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "class SensorDrift:\n",
    "    \"\"\"Simulate gradual sensor drift over time.\"\"\"\n",
    "    \n",
    "    def __init__(self, drift_rate=0.01, channel_prob=0.2):\n",
    "        self.drift_rate = drift_rate\n",
    "        self.channel_prob = channel_prob\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        T, C = x.shape[-2], x.shape[-1]\n",
    "        result = x.clone()\n",
    "        \n",
    "        # Select channels to apply drift\n",
    "        drift_channels = torch.rand(C) < self.channel_prob\n",
    "        \n",
    "        # Create linear drift\n",
    "        t = torch.linspace(0, 1, T).unsqueeze(-1)\n",
    "        drift = t * (torch.rand(C) * 2 - 1) * self.drift_rate\n",
    "        drift[:, ~drift_channels] = 0\n",
    "        \n",
    "        if result.dim() == 3:\n",
    "            drift = drift.unsqueeze(0)\n",
    "        \n",
    "        return result + drift\n",
    "\n",
    "\n",
    "# Define sensor groups (hypothetical)\n",
    "sensor_groups = {\n",
    "    'position': slice(0, 30),\n",
    "    'velocity': slice(30, 60),\n",
    "    'acceleration': slice(60, 90),\n",
    "    'force': slice(90, 120),\n",
    "    'temperature': slice(120, 140),\n",
    "    'misc': slice(140, 155)\n",
    "}\n",
    "\n",
    "# Test sensor-specific augmentations\n",
    "sensor_augs = {\n",
    "    'Sensor Mask': SensorGroupMask(sensor_groups, mask_prob=0.3),\n",
    "    'Motion Perturb': MotionProfilePerturbation(velocity_noise=0.1),\n",
    "    'Sensor Drift': SensorDrift(drift_rate=0.05, channel_prob=0.3),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "channel = 35  # Velocity channel\n",
    "axes[0, 0].plot(vis_sample[:, channel].numpy())\n",
    "axes[0, 0].set_title(f'Original (Channel {channel})')\n",
    "\n",
    "for ax, (name, aug) in zip(axes.flat[1:], sensor_augs.items()):\n",
    "    augmented = aug(vis_sample.clone())\n",
    "    ax.plot(augmented[:, channel].numpy())\n",
    "    ax.set_title(name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'reports' / 'sensor_augmentations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Augmentation Pipeline\n",
    "\n",
    "Combine augmentations into a configurable pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AugmentationConfig:\n",
    "    \"\"\"Configuration for augmentation pipeline.\"\"\"\n",
    "    time_warp_prob: float = 0.3\n",
    "    time_warp_sigma: float = 0.1\n",
    "    noise_prob: float = 0.5\n",
    "    noise_std: float = 0.1\n",
    "    scaling_prob: float = 0.3\n",
    "    scaling_sigma: float = 0.1\n",
    "    magnitude_warp_prob: float = 0.3\n",
    "    channel_dropout_prob: float = 0.2\n",
    "    channel_dropout_rate: float = 0.1\n",
    "    time_shift_prob: float = 0.2\n",
    "    mixup_prob: float = 0.0  # Applied at batch level\n",
    "    cutmix_prob: float = 0.0\n",
    "\n",
    "\n",
    "class AugmentationPipeline:\n",
    "    \"\"\"Composable augmentation pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: AugmentationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "        # Initialize augmentations\n",
    "        self.augmentations = [\n",
    "            (config.time_warp_prob, TimeWarping(sigma=config.time_warp_sigma)),\n",
    "            (config.noise_prob, GaussianNoise(std=config.noise_std)),\n",
    "            (config.scaling_prob, Scaling(sigma=config.scaling_sigma)),\n",
    "            (config.magnitude_warp_prob, MagnitudeWarping(sigma=0.2)),\n",
    "            (config.channel_dropout_prob, ChannelDropout(p=config.channel_dropout_rate)),\n",
    "            (config.time_shift_prob, TimeShift(max_shift_ratio=0.1)),\n",
    "        ]\n",
    "        \n",
    "        self.mixup = Mixup(alpha=0.4) if config.mixup_prob > 0 else None\n",
    "        self.cutmix = CutMix(alpha=1.0) if config.cutmix_prob > 0 else None\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Apply random augmentations.\"\"\"\n",
    "        result = x.clone()\n",
    "        \n",
    "        for prob, aug in self.augmentations:\n",
    "            if random.random() < prob:\n",
    "                result = aug(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def augment_batch(self, batch: torch.Tensor, \n",
    "                      targets: Optional[torch.Tensor] = None\n",
    "                     ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        \"\"\"Augment a batch with mixing strategies.\"\"\"\n",
    "        B = batch.shape[0]\n",
    "        \n",
    "        # Apply per-sample augmentations\n",
    "        augmented = torch.stack([self(batch[i]) for i in range(B)])\n",
    "        \n",
    "        # Apply mixup/cutmix\n",
    "        if self.mixup and random.random() < self.config.mixup_prob:\n",
    "            indices = torch.randperm(B)\n",
    "            augmented, targets, _ = self.mixup(\n",
    "                augmented, augmented[indices], \n",
    "                targets, targets[indices] if targets is not None else None\n",
    "            )\n",
    "        elif self.cutmix and random.random() < self.config.cutmix_prob:\n",
    "            indices = torch.randperm(B)\n",
    "            augmented, targets, _ = self.cutmix(\n",
    "                augmented, augmented[indices],\n",
    "                targets, targets[indices] if targets is not None else None\n",
    "            )\n",
    "        \n",
    "        return augmented, targets\n",
    "\n",
    "\n",
    "# Create pipeline with default config\n",
    "config = AugmentationConfig()\n",
    "pipeline = AugmentationPipeline(config)\n",
    "\n",
    "# Apply to batch\n",
    "augmented_batch, _ = pipeline.augment_batch(sample_continuous)\n",
    "\n",
    "print(f\"Original batch shape: {sample_continuous.shape}\")\n",
    "print(f\"Augmented batch shape: {augmented_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multiple augmented versions of same sample\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n",
    "\n",
    "channel = 0\n",
    "axes[0, 0].plot(vis_sample[:, channel].numpy())\n",
    "axes[0, 0].set_title('Original')\n",
    "\n",
    "for ax in axes.flat[1:]:\n",
    "    augmented = pipeline(vis_sample)\n",
    "    ax.plot(augmented[:, channel].numpy())\n",
    "    ax.set_title('Augmented')\n",
    "\n",
    "plt.suptitle('Multiple Random Augmentations of Same Sample', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'reports' / 'augmentation_pipeline.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation with Augmentation\n",
    "\n",
    "Test how augmentation affects model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset wrapper with online augmentation.\"\"\"\n",
    "    \n",
    "    def __init__(self, continuous, categorical, targets=None, \n",
    "                 augmentation_pipeline=None, training=True):\n",
    "        self.continuous = continuous\n",
    "        self.categorical = categorical\n",
    "        self.targets = targets\n",
    "        self.pipeline = augmentation_pipeline\n",
    "        self.training = training\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.continuous)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.continuous[idx]\n",
    "        cat = self.categorical[idx]\n",
    "        \n",
    "        if self.training and self.pipeline:\n",
    "            x = self.pipeline(x)\n",
    "        \n",
    "        if self.targets is not None:\n",
    "            return x, cat, self.targets[idx]\n",
    "        return x, cat\n",
    "\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_dataset = AugmentedDataset(\n",
    "    sample_continuous,\n",
    "    sample_categorical,\n",
    "    augmentation_pipeline=pipeline,\n",
    "    training=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(augmented_dataset)}\")\n",
    "print(f\"Sample shape: {augmented_dataset[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation strength analysis\n",
    "def analyze_augmentation_strength(pipeline, sample, n_augmentations=100):\n",
    "    \"\"\"Analyze how much augmentation changes the data.\"\"\"\n",
    "    augmented_samples = torch.stack([pipeline(sample) for _ in range(n_augmentations)])\n",
    "    \n",
    "    # Compute statistics\n",
    "    mean_diff = (augmented_samples - sample.unsqueeze(0)).abs().mean(dim=0)\n",
    "    std_across_augs = augmented_samples.std(dim=0)\n",
    "    \n",
    "    return {\n",
    "        'mean_abs_diff': mean_diff.mean().item(),\n",
    "        'max_abs_diff': mean_diff.max().item(),\n",
    "        'augmentation_std': std_across_augs.mean().item(),\n",
    "        'per_channel_diff': mean_diff.mean(dim=0)\n",
    "    }\n",
    "\n",
    "# Analyze default pipeline\n",
    "stats = analyze_augmentation_strength(pipeline, vis_sample)\n",
    "\n",
    "print(\"Augmentation Strength Analysis:\")\n",
    "print(f\"  Mean absolute difference: {stats['mean_abs_diff']:.4f}\")\n",
    "print(f\"  Max absolute difference: {stats['max_abs_diff']:.4f}\")\n",
    "print(f\"  Augmentation std: {stats['augmentation_std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different augmentation configurations\n",
    "configs = {\n",
    "    'Light': AugmentationConfig(\n",
    "        noise_prob=0.3, noise_std=0.05,\n",
    "        scaling_prob=0.2, scaling_sigma=0.05,\n",
    "        time_warp_prob=0.1, time_warp_sigma=0.05\n",
    "    ),\n",
    "    'Medium': AugmentationConfig(\n",
    "        noise_prob=0.5, noise_std=0.1,\n",
    "        scaling_prob=0.3, scaling_sigma=0.1,\n",
    "        time_warp_prob=0.3, time_warp_sigma=0.1\n",
    "    ),\n",
    "    'Heavy': AugmentationConfig(\n",
    "        noise_prob=0.7, noise_std=0.2,\n",
    "        scaling_prob=0.5, scaling_sigma=0.2,\n",
    "        time_warp_prob=0.5, time_warp_sigma=0.2,\n",
    "        channel_dropout_prob=0.3\n",
    "    ),\n",
    "}\n",
    "\n",
    "strength_comparison = {}\n",
    "for name, cfg in configs.items():\n",
    "    pipe = AugmentationPipeline(cfg)\n",
    "    stats = analyze_augmentation_strength(pipe, vis_sample, n_augmentations=50)\n",
    "    strength_comparison[name] = stats\n",
    "    print(f\"{name}: mean_diff={stats['mean_abs_diff']:.4f}, std={stats['augmentation_std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save augmentation configuration\n",
    "aug_config_dict = {\n",
    "    'light': {\n",
    "        'noise_prob': 0.3, 'noise_std': 0.05,\n",
    "        'scaling_prob': 0.2, 'scaling_sigma': 0.05,\n",
    "        'time_warp_prob': 0.1, 'time_warp_sigma': 0.05\n",
    "    },\n",
    "    'medium': {\n",
    "        'noise_prob': 0.5, 'noise_std': 0.1,\n",
    "        'scaling_prob': 0.3, 'scaling_sigma': 0.1,\n",
    "        'time_warp_prob': 0.3, 'time_warp_sigma': 0.1\n",
    "    },\n",
    "    'heavy': {\n",
    "        'noise_prob': 0.7, 'noise_std': 0.2,\n",
    "        'scaling_prob': 0.5, 'scaling_sigma': 0.2,\n",
    "        'time_warp_prob': 0.5, 'time_warp_sigma': 0.2,\n",
    "        'channel_dropout_prob': 0.3\n",
    "    }\n",
    "}\n",
    "\n",
    "config_path = project_root / 'configs' / 'augmentation_configs.json'\n",
    "config_path.parent.mkdir(exist_ok=True)\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(aug_config_dict, f, indent=2)\n",
    "\n",
    "print(f\"Augmentation configs saved to: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook provides comprehensive data augmentation for sensor time series:\n",
    "\n",
    "1. **Time-Domain**: Time warping, window slicing, random crop, time shift\n",
    "2. **Magnitude**: Gaussian noise, scaling, magnitude warping, channel dropout\n",
    "3. **Mixing**: Mixup, CutMix, Temporal CutMix for regularization\n",
    "4. **Sensor-Specific**: Sensor group masking, axis permutation, drift simulation\n",
    "5. **Pipeline**: Configurable, composable augmentation pipeline\n",
    "6. **Evaluation**: Strength analysis and configuration comparison\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation:**\n",
    "← [Previous: 14_robustness_testing](14_robustness_testing.ipynb) |\n",
    "[Next: 16_architecture_comparison](16_architecture_comparison.ipynb) →"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
