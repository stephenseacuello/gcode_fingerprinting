{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 01 - Getting Started with G-code Fingerprinting\n",
    "\n",
    "Welcome! This notebook provides a complete introduction to the G-code fingerprinting project.\n",
    "\n",
    "## Table of Contents\n",
    "1. [What is G-code Fingerprinting?](#1.-What-is-G-code-Fingerprinting?)\n",
    "2. [Project Architecture](#2.-Project-Architecture)\n",
    "3. [Environment Setup](#3.-Environment-Setup)\n",
    "4. [Project Structure](#4.-Project-Structure)\n",
    "5. [Understanding the Model](#5.-Understanding-the-Model)\n",
    "6. [Data Format](#6.-Data-Format)\n",
    "7. [Quick Inference Demo](#7.-Quick-Inference-Demo)\n",
    "8. [Next Steps](#8.-Next-Steps)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. What is G-code Fingerprinting?\n",
    "\n",
    "This project uses deep learning to:\n",
    "\n",
    "1. **Predict G-code sequences** from CNC machine sensor data\n",
    "2. **Classify operation types** with near-perfect accuracy\n",
    "3. **Extract machine fingerprints** - unique embeddings that identify specific operations\n",
    "\n",
    "### Use Cases\n",
    "- **Manufacturing Quality Control**: Verify machine operations match expected G-code\n",
    "- **Security**: Detect unauthorized modifications to machine programs\n",
    "- **Process Monitoring**: Understand what a machine is doing from sensor data alone\n",
    "- **Digital Twins**: Create models that map sensor patterns to machine commands\n",
    "\n",
    "### Key Innovations\n",
    "- **Two-Stage Architecture**: Frozen MM-DTAE-LSTM encoder + SensorMultiHeadDecoder\n",
    "- **Multi-Head Prediction**: Separate heads for type, command, param_type, and digit values\n",
    "- **Operation Conditioning**: Leverages 100% accurate operation classification to guide token generation\n",
    "- **Digit-by-Digit Value Prediction**: Predicts numeric values one digit at a time (4-digit precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 2. Project Architecture\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────────┐\n",
    "│                    G-code Fingerprinting Pipeline (v3)                          │\n",
    "└─────────────────────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌─────────────────┐    ┌────────────────────────┐    ┌─────────────────────────┐\n",
    "│   Sensor Data   │    │   MM-DTAE-LSTM v2      │    │   Operation Type        │\n",
    "│ (155 cont + 4   │───▶│      (FROZEN)          │───▶│   Classification        │\n",
    "│   categorical)  │    │   Encoder              │    │   (100% accurate!)      │\n",
    "└─────────────────┘    └────────────────────────┘    └─────────────────────────┘\n",
    "                               │                                │\n",
    "                               │ sensor_embeddings              │ operation_type\n",
    "                               │ [B, 64, 128]                   │ [B]\n",
    "                               ▼                                ▼\n",
    "                       ┌─────────────────────────────────────────────────┐\n",
    "                       │        SensorMultiHeadDecoder v3                │\n",
    "                       │  ┌─────────────────────────────────────────┐   │\n",
    "                       │  │  Operation Embedding + Sensor Projection │   │\n",
    "                       │  └─────────────────────────────────────────┘   │\n",
    "                       │                      │                          │\n",
    "                       │  ┌───────────────────▼──────────────────────┐  │\n",
    "                       │  │  Transformer Decoder (4 layers, 8 heads) │  │\n",
    "                       │  │     d_model=192, dropout=0.3             │  │\n",
    "                       │  └──────────────────────────────────────────┘  │\n",
    "                       │                      │                          │\n",
    "                       │           ┌─────────┴─────────┐                │\n",
    "                       │           ▼                   ▼                │\n",
    "                       │   ┌───────────────┐  ┌─────────────────┐       │\n",
    "                       │   │  Multi-Head   │  │  Digit Value    │       │\n",
    "                       │   │  Outputs:     │  │  Head:          │       │\n",
    "                       │   │  - type (4)   │  │  - sign (3)     │       │\n",
    "                       │   │  - cmd (6)    │  │  - 6 digits     │       │\n",
    "                       │   │  - param (10) │  │  - aux_value    │       │\n",
    "                       │   └───────────────┘  └─────────────────┘       │\n",
    "                       └─────────────────────────────────────────────────┘\n",
    "                                              │\n",
    "                                              ▼\n",
    "                               ┌─────────────────────────┐\n",
    "                               │  G-code Token Sequence  │\n",
    "                               │  (max 32 tokens)        │\n",
    "                               └─────────────────────────┘\n",
    "```\n",
    "\n",
    "### Components\n",
    "- **Sensor Data**: 155 continuous features + 4 categorical features (64 timesteps)\n",
    "- **MM-DTAE-LSTM v2**: Frozen encoder providing 128-dim embeddings + operation classification\n",
    "- **SensorMultiHeadDecoder v3**: Transformer decoder with operation conditioning and multi-head outputs\n",
    "- **Token Types**: SPECIAL, COMMAND, PARAM_LETTER, NUMERIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 3. Environment Setup\n",
    "\n",
    "Let's verify your environment is properly configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Environment Setup and Verification\n",
    "# ============================================================\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Project root setup\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"G-CODE FINGERPRINTING - ENVIRONMENT CHECK\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n✓ Project root: {project_root}\")\n",
    "print(f\"✓ Python path configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python version check\n",
    "print(f\"\\nPython Version: {sys.version}\")\n",
    "\n",
    "# Check Python version is compatible\n",
    "if sys.version_info >= (3, 9):\n",
    "    print(\"✓ Python version compatible (3.9+)\")\n",
    "else:\n",
    "    print(\"⚠ Python 3.9+ recommended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package version check\n",
    "packages_to_check = [\n",
    "    ('torch', 'PyTorch'),\n",
    "    ('numpy', 'NumPy'),\n",
    "    ('pandas', 'Pandas'),\n",
    "    ('matplotlib', 'Matplotlib'),\n",
    "    ('seaborn', 'Seaborn'),\n",
    "    ('sklearn', 'Scikit-learn'),\n",
    "    ('wandb', 'Weights & Biases'),\n",
    "    ('flask', 'Flask'),\n",
    "]\n",
    "\n",
    "print(\"\\nPackage Versions:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for pkg_name, display_name in packages_to_check:\n",
    "    try:\n",
    "        module = __import__(pkg_name)\n",
    "        version = getattr(module, '__version__', 'installed')\n",
    "        print(f\"  ✓ {display_name:20s} {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"  ✗ {display_name:20s} NOT INSTALLED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device check\n",
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"\\nCompute Device:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"  ✓ CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"    Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"  ✓ Apple MPS available (Metal Performance Shaders)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"  ℹ Using CPU (no GPU acceleration)\")\n",
    "\n",
    "print(f\"\\n  Selected device: {device}\")\n",
    "print(f\"\\n✓ Reproducibility seeds set (SEED={SEED})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Project Structure\n",
    "\n",
    "Understanding the project layout helps you navigate the codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify key directories exist\n",
    "print(\"\\nProject Structure:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "structure = {\n",
    "    'data/': 'Raw G-code files and vocabulary files',\n",
    "    'src/miracle/': 'Core Python package',\n",
    "    'src/miracle/model/': 'Model architectures (MM-DTAE-LSTM, SensorMultiHeadDecoder)',\n",
    "    'src/miracle/dataset/': 'Data loading and preprocessing',\n",
    "    'src/miracle/training/': 'Training utilities and losses',\n",
    "    'scripts/': 'Training and evaluation scripts',\n",
    "    'configs/': 'Configuration files',\n",
    "    'outputs/': 'Model checkpoints and results',\n",
    "    'outputs/sensor_multihead_v3/': 'Latest trained model (decoder)',\n",
    "    'outputs/mm_dtae_lstm_v2/': 'Frozen encoder model',\n",
    "    'outputs/stratified_splits_v2/': 'Train/val/test splits',\n",
    "    'notebooks/': 'Tutorial notebooks (you are here!)',\n",
    "}\n",
    "\n",
    "for path, description in structure.items():\n",
    "    full_path = project_root / path.rstrip('/')\n",
    "    exists = \"✓\" if full_path.exists() else \"✗\"\n",
    "    print(f\"  {exists} {path:40s} {description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for critical files\n",
    "print(\"\\nCritical Files:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "critical_files = {\n",
    "    'data/vocabulary_4digit_hybrid.json': 'G-code vocabulary (4-digit hybrid)',\n",
    "    'outputs/stratified_splits_v2/train_sequences.npz': 'Training data',\n",
    "    'outputs/stratified_splits_v2/val_sequences.npz': 'Validation data',\n",
    "    'outputs/stratified_splits_v2/test_sequences.npz': 'Test data',\n",
    "    'outputs/sensor_multihead_v3/best_model.pt': 'Best decoder model',\n",
    "    'outputs/mm_dtae_lstm_v2/best_model.pt': 'Frozen encoder model',\n",
    "}\n",
    "\n",
    "for path, description in critical_files.items():\n",
    "    full_path = project_root / path\n",
    "    if full_path.exists():\n",
    "        size_mb = full_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  ✓ {path:50s} ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"  ✗ {path:50s} (MISSING)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Understanding the Model\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "The model uses a two-stage architecture:\n",
    "\n",
    "**Stage 1: MM-DTAE-LSTM Encoder (Frozen)**\n",
    "- Processes raw sensor data (155 continuous + 4 categorical features)\n",
    "- Outputs 128-dimensional embeddings\n",
    "- Classifies operation type with ~100% accuracy\n",
    "\n",
    "**Stage 2: SensorMultiHeadDecoder**\n",
    "- Receives sensor embeddings and operation type\n",
    "- Generates G-code tokens autoregressively\n",
    "- Multi-head outputs for structured prediction\n",
    "\n",
    "### Token Types\n",
    "\n",
    "| Type ID | Type Name | Examples |\n",
    "|---------|-----------|----------|\n",
    "| 0 | SPECIAL | PAD, BOS, EOS, UNK |\n",
    "| 1 | COMMAND | G0, G1, G2, G3, G53, M30 |\n",
    "| 2 | PARAM_LETTER | X, Y, Z, F, R |\n",
    "| 3 | NUMERIC | NUM_X_1234 (4-digit values) |\n",
    "\n",
    "### Operation Types (9 classes)\n",
    "\n",
    "The model identifies 9 distinct machining operations from sensor patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display model configuration\n",
    "import json\n",
    "\n",
    "results_path = project_root / 'outputs' / 'sensor_multihead_v3' / 'results.json'\n",
    "\n",
    "if results_path.exists():\n",
    "    with open(results_path, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    args = results.get('args', {})\n",
    "    \n",
    "    print(\"\\nModel Configuration (SensorMultiHeadDecoder v3):\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"  d_model:        {args.get('d_model', 'N/A')}\")\n",
    "    print(f\"  n_heads:        {args.get('n_heads', 'N/A')}\")\n",
    "    print(f\"  n_layers:       {args.get('n_layers', 'N/A')}\")\n",
    "    print(f\"  dropout:        {args.get('dropout', 'N/A')}\")\n",
    "    print(f\"  sensor_dim:     {args.get('sensor_dim', 'N/A')}\")\n",
    "    print(f\"  n_operations:   {args.get('n_operations', 'N/A')}\")\n",
    "    print(f\"  n_types:        {args.get('n_types', 'N/A')}\")\n",
    "    print(f\"  n_commands:     {args.get('n_commands', 'N/A')}\")\n",
    "    print(f\"  n_param_types:  {args.get('n_param_types', 'N/A')}\")\n",
    "    print(f\"  max_seq_len:    {args.get('max_seq_len', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\nTraining Configuration:\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"  batch_size:     {args.get('batch_size', 'N/A')}\")\n",
    "    print(f\"  max_epochs:     {args.get('max_epochs', 'N/A')}\")\n",
    "    print(f\"  learning_rate:  {args.get('learning_rate', 'N/A')}\")\n",
    "    print(f\"  use_focal_loss: {args.get('use_focal_loss', 'N/A')}\")\n",
    "    print(f\"  focal_gamma:    {args.get('focal_gamma', 'N/A')}\")\n",
    "    print(f\"  curriculum:     {args.get('curriculum', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\nPerformance:\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"  Best val token accuracy: {results.get('best_val_metric', 0):.2%}\")\n",
    "    test_metrics = results.get('test_metrics', {})\n",
    "    print(f\"  Test token accuracy:     {test_metrics.get('token', 0):.2%}\")\n",
    "    print(f\"  Test loss:               {test_metrics.get('loss', 0):.4f}\")\n",
    "else:\n",
    "    print(\"⚠ Results file not found. Train a model first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabulary and show statistics\n",
    "vocab_path = project_root / 'data' / 'vocabulary_4digit_hybrid.json'\n",
    "\n",
    "if vocab_path.exists():\n",
    "    with open(vocab_path, 'r') as f:\n",
    "        vocab_data = json.load(f)\n",
    "    \n",
    "    vocab = vocab_data.get('vocab', vocab_data)  # Handle nested or flat format\n",
    "    config = vocab_data.get('config', {})\n",
    "    \n",
    "    print(\"\\nVocabulary Statistics (4-digit hybrid):\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"  Total tokens: {len(vocab)}\")\n",
    "    \n",
    "    # Categorize tokens\n",
    "    commands = [t for t in vocab.keys() if t.startswith('G') or t.startswith('M')]\n",
    "    param_letters = [t for t in vocab.keys() if t in ['X', 'Y', 'Z', 'F', 'R', 'S', 'I', 'J', 'K', 'A', 'B', 'C']]\n",
    "    numeric = [t for t in vocab.keys() if t.startswith('NUM_')]\n",
    "    special = [t for t in vocab.keys() if t in ['PAD', 'BOS', 'EOS', 'UNK', 'MASK']]\n",
    "    \n",
    "    print(f\"  Special tokens:     {len(special)}\")\n",
    "    print(f\"  Command tokens:     {len(commands)}\")\n",
    "    print(f\"  Parameter letters:  {len(param_letters)}\")\n",
    "    print(f\"  Numeric tokens:     {len(numeric)}\")\n",
    "    \n",
    "    print(f\"\\nSample tokens:\")\n",
    "    print(f\"  Special:    {special}\")\n",
    "    print(f\"  Commands:   {commands[:8]}\")\n",
    "    print(f\"  Param:      {param_letters[:8]}\")\n",
    "    print(f\"  Numeric:    {list(numeric)[:5]}...\")\n",
    "    \n",
    "    if config:\n",
    "        print(f\"\\nVocab Config:\")\n",
    "        print(f\"  Mode:           {config.get('mode', 'N/A')}\")\n",
    "        print(f\"  Bucket digits:  {config.get('bucket_digits', 'N/A')}\")\n",
    "else:\n",
    "    print(\"⚠ Vocabulary not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 6. Data Format\n",
    "\n",
    "The preprocessed data is stored in `.npz` format with the following structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect data format\n",
    "split_dir = project_root / 'outputs' / 'stratified_splits_v2'\n",
    "\n",
    "if (split_dir / 'train_sequences.npz').exists():\n",
    "    train_data = np.load(split_dir / 'train_sequences.npz', allow_pickle=True)\n",
    "    \n",
    "    print(\"\\nTraining Data Structure:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for key in train_data.keys():\n",
    "        arr = train_data[key]\n",
    "        if hasattr(arr, 'shape'):\n",
    "            print(f\"  {key:25s} shape={str(arr.shape):20s} dtype={arr.dtype}\")\n",
    "        else:\n",
    "            print(f\"  {key:25s} type={type(arr).__name__}\")\n",
    "    \n",
    "    print(f\"\\nData Description:\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"  continuous:       Sensor continuous features [N, 64, 155]\")\n",
    "    print(f\"  categorical:      Sensor categorical features [N, 64, 4]\")\n",
    "    print(f\"  tokens:           G-code token IDs [N, seq_len]\")\n",
    "    print(f\"  param_value_raw:  Raw numeric values [N, seq_len]\")\n",
    "    print(f\"  operation_type:   Operation type labels [N]\")\n",
    "    print(f\"  gcode_texts:      Original G-code strings [N]\")\n",
    "    print(f\"  lengths:          Sequence lengths [N]\")\n",
    "    \n",
    "    print(f\"\\nSample sizes:\")\n",
    "    print(f\"  Training:   {len(train_data['continuous']):,} samples\")\n",
    "    \n",
    "    if (split_dir / 'val_sequences.npz').exists():\n",
    "        val_data = np.load(split_dir / 'val_sequences.npz', allow_pickle=True)\n",
    "        print(f\"  Validation: {len(val_data['continuous']):,} samples\")\n",
    "    \n",
    "    if (split_dir / 'test_sequences.npz').exists():\n",
    "        test_data = np.load(split_dir / 'test_sequences.npz', allow_pickle=True)\n",
    "        print(f\"  Test:       {len(test_data['continuous']):,} samples\")\n",
    "else:\n",
    "    print(\"⚠ Training data not found. Run preprocessing first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample data\n",
    "if (split_dir / 'train_sequences.npz').exists():\n",
    "    print(\"\\nSample Data (first 3 samples):\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i in range(min(3, len(train_data['gcode_texts']))):\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"  Operation type: {train_data['operation_type'][i]}\")\n",
    "        if 'operation_type_names' in train_data:\n",
    "            print(f\"  Operation name: {train_data['operation_type_names'][i]}\")\n",
    "        print(f\"  Sensor shape:   continuous={train_data['continuous'][i].shape}\")\n",
    "        print(f\"  Token IDs:      {train_data['tokens'][i][:10]}...\")\n",
    "        print(f\"  G-code text:    {train_data['gcode_texts'][i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 7. Quick Inference Demo\n",
    "\n",
    "Let's load a trained model and run inference on sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find available checkpoints\n",
    "import glob\n",
    "\n",
    "checkpoint_patterns = [\n",
    "    'outputs/sensor_multihead_v3/best_model.pt',\n",
    "    'outputs/*/best_model.pt',\n",
    "    'outputs/*/checkpoint_best.pt',\n",
    "]\n",
    "\n",
    "checkpoints = []\n",
    "for pattern in checkpoint_patterns:\n",
    "    checkpoints.extend(glob.glob(str(project_root / pattern)))\n",
    "\n",
    "print(\"\\nAvailable Checkpoints:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if checkpoints:\n",
    "    for cp in checkpoints[:5]:\n",
    "        cp_path = Path(cp)\n",
    "        size_mb = cp_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  • {cp_path.relative_to(project_root)} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    # Prefer sensor_multihead_v3\n",
    "    preferred = project_root / 'outputs' / 'sensor_multihead_v3' / 'best_model.pt'\n",
    "    checkpoint_path = str(preferred) if preferred.exists() else checkpoints[0]\n",
    "    print(f\"\\n  Using: {Path(checkpoint_path).relative_to(project_root)}\")\n",
    "else:\n",
    "    print(\"  ⚠ No checkpoints found. Train a model first!\")\n",
    "    checkpoint_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint and model\n",
    "if checkpoint_path and vocab_path.exists():\n",
    "    print(\"\\nLoading checkpoint...\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    print(\"\\nCheckpoint Contents:\")\n",
    "    print(\"-\" * 40)\n",
    "    for key in checkpoint.keys():\n",
    "        if 'state_dict' in key:\n",
    "            print(f\"  {key}: {len(checkpoint[key])} parameters\")\n",
    "        elif isinstance(checkpoint[key], dict):\n",
    "            print(f\"  {key}: dict with {len(checkpoint[key])} keys\")\n",
    "        else:\n",
    "            print(f\"  {key}: {type(checkpoint[key]).__name__}\")\n",
    "    \n",
    "    print(\"\\n✓ Checkpoint loaded successfully!\")\n",
    "else:\n",
    "    print(\"⚠ Skipping model loading - missing checkpoint or vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model architecture\n",
    "if checkpoint_path:\n",
    "    try:\n",
    "        from miracle.model.sensor_multihead_decoder import SensorMultiHeadDecoder\n",
    "        \n",
    "        # Get model config from checkpoint or use defaults\n",
    "        config = checkpoint.get('config', {}) or {}\n",
    "        \n",
    "        model = SensorMultiHeadDecoder(\n",
    "            vocab_size=config.get('vocab_size', 668),\n",
    "            d_model=config.get('d_model', 192),\n",
    "            n_heads=config.get('n_heads', 8),\n",
    "            n_layers=config.get('n_layers', 4),\n",
    "            sensor_dim=config.get('sensor_dim', 128),\n",
    "            n_operations=config.get('n_operations', 9),\n",
    "            n_types=config.get('n_types', 4),\n",
    "            n_commands=config.get('n_commands', 6),\n",
    "            n_param_types=config.get('n_param_types', 10),\n",
    "            dropout=0.0,  # No dropout for inference\n",
    "        ).to(device)\n",
    "        \n",
    "        # Load weights\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        # Count parameters\n",
    "        param_counts = model.count_parameters()\n",
    "        print(\"\\nModel Parameter Counts:\")\n",
    "        print(\"-\" * 40)\n",
    "        for name, count in param_counts.items():\n",
    "            print(f\"  {name:25s} {count:,}\")\n",
    "        \n",
    "        print(f\"\\n✓ Model loaded successfully!\")\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"⚠ Could not import model: {e}\")\n",
    "        model = None\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Could not load model: {e}\")\n",
    "        model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run quick inference with synthetic data\n",
    "if checkpoint_path and 'model' in dir() and model is not None:\n",
    "    import time\n",
    "    \n",
    "    print(\"\\nRunning inference on synthetic data...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Generate synthetic inputs\n",
    "    batch_size = 2\n",
    "    sensor_seq_len = 50\n",
    "    token_seq_len = 16\n",
    "    sensor_dim = 128\n",
    "    n_operations = 9\n",
    "    vocab_size = 668\n",
    "    \n",
    "    # Synthetic sensor embeddings (normally from MM-DTAE-LSTM encoder)\n",
    "    sensor_embeddings = torch.randn(batch_size, sensor_seq_len, sensor_dim).to(device)\n",
    "    operation_type = torch.randint(0, n_operations, (batch_size,)).to(device)\n",
    "    tokens = torch.randint(0, vocab_size, (batch_size, token_seq_len)).to(device)\n",
    "    \n",
    "    print(f\"  Input shapes:\")\n",
    "    print(f\"    sensor_embeddings: {sensor_embeddings.shape}\")\n",
    "    print(f\"    operation_type:    {operation_type.shape}\")\n",
    "    print(f\"    tokens:            {tokens.shape}\")\n",
    "    \n",
    "    # Forward pass\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens, sensor_embeddings, operation_type)\n",
    "    inference_time = (time.time() - start_time) * 1000\n",
    "    \n",
    "    print(f\"\\n  Output shapes:\")\n",
    "    for name, tensor in outputs.items():\n",
    "        if tensor is not None:\n",
    "            print(f\"    {name:20s} {tensor.shape}\")\n",
    "    \n",
    "    print(f\"\\n  Inference time: {inference_time:.2f} ms\")\n",
    "    print(f\"\\n✓ Inference successful!\")\n",
    "else:\n",
    "    print(\"⚠ Skipping inference demo - model not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "### Recommended Tutorial Sequence\n",
    "\n",
    "| # | Notebook | Description |\n",
    "|---|----------|-------------|\n",
    "| 00 | [Raw Data Analysis](00_raw_data_analysis.ipynb) | Explore the raw dataset |\n",
    "| **01** | **Getting Started** | **You are here!** |\n",
    "| 02 | [Data Preprocessing](02_data_preprocessing.ipynb) | Prepare data for training |\n",
    "| 03 | [Training Models](03_training_models.ipynb) | Train from scratch |\n",
    "| 04 | [Inference & Prediction](04_inference_prediction.ipynb) | Run predictions |\n",
    "| 05 | [API Usage](05_api_usage.ipynb) | Use the REST API |\n",
    "| 06 | [Dashboard Usage](06_dashboard_usage.ipynb) | Interactive dashboard |\n",
    "| 07 | [Hyperparameter Sweeps](07_hyperparameter_sweeps.ipynb) | Optimize with W&B |\n",
    "| 08 | [Model Evaluation](08_model_evaluation.ipynb) | Comprehensive eval |\n",
    "| 09 | [Ablation Studies](09_ablation_studies.ipynb) | Component analysis |\n",
    "| 10 | [Visualization Experiments](10_visualization_experiments.ipynb) | Publication figures |\n",
    "\n",
    "### Quick Start Commands\n",
    "\n",
    "```bash\n",
    "# Create stratified splits\n",
    "PYTHONPATH=src .venv/bin/python scripts/create_stratified_splits.py \\\n",
    "    --data-dir data \\\n",
    "    --output-dir outputs/stratified_splits_v2\n",
    "\n",
    "# Train sensor multi-head decoder\n",
    "PYTORCH_ENABLE_MPS_FALLBACK=1 PYTHONPATH=src .venv/bin/python scripts/train_sensor_multihead.py \\\n",
    "    --split-dir outputs/stratified_splits_v2 \\\n",
    "    --vocab-path data/vocabulary_4digit_hybrid.json \\\n",
    "    --encoder-path outputs/mm_dtae_lstm_v2/best_model.pt \\\n",
    "    --output-dir outputs/sensor_multihead_v3 \\\n",
    "    --use-wandb\n",
    "\n",
    "# Start dashboard\n",
    "PYTHONPATH=src .venv/bin/python flask_dashboard.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "- **Project purpose**: Predict G-code from sensor data with high accuracy (~90%+)\n",
    "- **Architecture**: Frozen MM-DTAE-LSTM encoder + SensorMultiHeadDecoder\n",
    "- **Data format**: NPZ files with sensor, tokens, operation types\n",
    "- **Token types**: SPECIAL, COMMAND, PARAM_LETTER, NUMERIC (4 types)\n",
    "- **Operations**: 9 distinct machining operation classes\n",
    "\n",
    "### Key Model Features\n",
    "\n",
    "| Feature | Value |\n",
    "|---------|-------|\n",
    "| d_model | 192 |\n",
    "| n_heads | 8 |\n",
    "| n_layers | 4 |\n",
    "| sensor_dim | 128 |\n",
    "| Token accuracy | ~90%+ |\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "| Issue | Solution |\n",
    "|-------|----------|\n",
    "| Import errors | Activate venv, set `PYTHONPATH=src` |\n",
    "| No checkpoints | Train a model first |\n",
    "| Vocabulary missing | Check `data/vocabulary_4digit_hybrid.json` |\n",
    "| CUDA errors | Use CPU or enable MPS fallback |\n",
    "| Memory errors | Reduce batch size |\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation:**\n",
    "← [Previous: 00_raw_data_analysis](00_raw_data_analysis.ipynb) |\n",
    "[Next: 02_data_preprocessing](02_data_preprocessing.ipynb) →\n",
    "\n",
    "**Related:** [03_training_models](03_training_models.ipynb) | [08_model_evaluation](08_model_evaluation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
