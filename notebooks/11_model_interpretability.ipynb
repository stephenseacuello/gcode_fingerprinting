{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 - Model Interpretability\n",
    "\n",
    "Understand how the model makes predictions through attention visualization, gradient analysis, and feature importance.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Overview](#1.-Overview)\n",
    "2. [Setup & Model Loading](#2.-Setup-&-Model-Loading)\n",
    "3. [Attention Weight Visualization](#3.-Attention-Weight-Visualization)\n",
    "4. [Gradient-Based Saliency](#4.-Gradient-Based-Saliency)\n",
    "5. [Per-Head Analysis](#5.-Per-Head-Analysis)\n",
    "6. [Sensor Importance Ranking](#6.-Sensor-Importance-Ranking)\n",
    "7. [Embedding Space Visualization](#7.-Embedding-Space-Visualization)\n",
    "8. [Token Prediction Analysis](#8.-Token-Prediction-Analysis)\n",
    "9. [Interpretability Summary](#9.-Interpretability-Summary)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview\n",
    "\n",
    "Model interpretability helps us understand:\n",
    "\n",
    "- **What sensors matter?** Which of the 155 sensor channels drive predictions?\n",
    "- **What temporal patterns?** Which timesteps are most important?\n",
    "- **How do heads specialize?** Do different heads focus on different tasks?\n",
    "- **Where does the model attend?** Attention patterns in the transformer.\n",
    "\n",
    "### Interpretability Methods\n",
    "\n",
    "| Method | What it Reveals | Computation |\n",
    "|--------|-----------------|-------------|\n",
    "| Attention Weights | Where model \"looks\" | Forward pass |\n",
    "| Gradient Saliency | Input sensitivity | Backward pass |\n",
    "| Integrated Gradients | Attribution scores | Multiple passes |\n",
    "| Head Ablation | Head importance | Forward passes |\n",
    "| Embedding Analysis | Learned representations | Forward pass |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Environment Setup\n",
    "# ============================================================\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Project root\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL INTERPRETABILITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup & Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and data\n",
    "from miracle.model.model import MM_DTAE_LSTM, ModelConfig\n",
    "from miracle.model.multihead_lm import MultiHeadGCodeLM\n",
    "from miracle.dataset.target_utils import TokenDecomposer\n",
    "\n",
    "# Find checkpoint\n",
    "import glob\n",
    "checkpoints = glob.glob(str(project_root / 'outputs/*/checkpoint_best.pt'))\n",
    "checkpoint_path = checkpoints[0] if checkpoints else None\n",
    "\n",
    "vocab_path = project_root / 'data' / 'gcode_vocab_v2.json'\n",
    "\n",
    "if checkpoint_path and vocab_path.exists():\n",
    "    print(f\"Loading checkpoint: {Path(checkpoint_path).relative_to(project_root)}\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    config_dict = checkpoint.get('config', {})\n",
    "    \n",
    "    # Load vocabulary\n",
    "    with open(vocab_path, 'r') as f:\n",
    "        vocab = json.load(f)\n",
    "    \n",
    "    # Create decomposer\n",
    "    decomposer = TokenDecomposer(str(vocab_path))\n",
    "    \n",
    "    # Create models\n",
    "    model_config = ModelConfig(\n",
    "        sensor_dims=[155, 4],\n",
    "        d_model=config_dict.get('hidden_dim', 128),\n",
    "        lstm_layers=config_dict.get('lstm_layers', 2),\n",
    "        gcode_vocab=len(vocab),\n",
    "        n_heads=config_dict.get('n_heads', 4),\n",
    "    )\n",
    "    \n",
    "    backbone = MM_DTAE_LSTM(model_config).to(device)\n",
    "    backbone.load_state_dict(checkpoint['backbone_state_dict'])\n",
    "    backbone.eval()\n",
    "    \n",
    "    lm = MultiHeadGCodeLM(\n",
    "        hidden_dim=model_config.d_model,\n",
    "        n_types=decomposer.n_types,\n",
    "        n_commands=decomposer.n_commands,\n",
    "        n_param_types=decomposer.n_param_types,\n",
    "        n_param_values=decomposer.n_param_values,\n",
    "    ).to(device)\n",
    "    lm.load_state_dict(checkpoint['lm_state_dict'])\n",
    "    lm.eval()\n",
    "    \n",
    "    print(f\"\\n✓ Models loaded successfully\")\n",
    "    print(f\"  Backbone params: {sum(p.numel() for p in backbone.parameters()):,}\")\n",
    "    print(f\"  LM params: {sum(p.numel() for p in lm.parameters()):,}\")\n",
    "else:\n",
    "    print(\"⚠ Checkpoint or vocabulary not found\")\n",
    "    backbone, lm, decomposer = None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_path = project_root / 'outputs' / 'processed_v2' / 'test.pt'\n",
    "\n",
    "if test_path.exists():\n",
    "    test_data = torch.load(test_path, weights_only=False)\n",
    "    print(f\"\\nTest data loaded: {len(test_data)} samples\")\n",
    "    \n",
    "    # Get a few samples for analysis\n",
    "    n_samples = min(100, len(test_data))\n",
    "    sample_indices = np.random.choice(len(test_data), n_samples, replace=False)\n",
    "    \n",
    "    print(f\"Selected {n_samples} samples for analysis\")\n",
    "else:\n",
    "    print(\"⚠ Test data not found. Using synthetic data.\")\n",
    "    test_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Attention Weight Visualization\n",
    "\n",
    "Visualize where the model focuses its attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook to capture attention weights\n",
    "attention_weights = {}\n",
    "\n",
    "def get_attention_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        # Capture attention weights if available\n",
    "        if hasattr(module, 'attn_weights'):\n",
    "            attention_weights[name] = module.attn_weights.detach().cpu()\n",
    "        elif isinstance(output, tuple) and len(output) > 1:\n",
    "            # Some attention modules return (output, weights)\n",
    "            if output[1] is not None:\n",
    "                attention_weights[name] = output[1].detach().cpu()\n",
    "    return hook\n",
    "\n",
    "# Register hooks on attention layers\n",
    "hooks = []\n",
    "if backbone is not None:\n",
    "    for name, module in backbone.named_modules():\n",
    "        if 'attention' in name.lower() or 'attn' in name.lower():\n",
    "            hooks.append(module.register_forward_hook(get_attention_hook(name)))\n",
    "    \n",
    "    for name, module in lm.named_modules():\n",
    "        if 'attention' in name.lower() or 'attn' in name.lower():\n",
    "            hooks.append(module.register_forward_hook(get_attention_hook(f'lm.{name}')))\n",
    "    \n",
    "    print(f\"Registered {len(hooks)} attention hooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample and capture attention\n",
    "if backbone is not None:\n",
    "    # Create sample input\n",
    "    if test_data is not None:\n",
    "        sample = test_data[0]\n",
    "        continuous = sample['continuous'].unsqueeze(0).to(device)\n",
    "        categorical = sample['categorical'].unsqueeze(0).to(device)\n",
    "    else:\n",
    "        continuous = torch.randn(1, 64, 155).to(device)\n",
    "        categorical = torch.randint(0, 10, (1, 64, 4)).to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        hidden = backbone(continuous, categorical)\n",
    "        preds = lm(hidden)\n",
    "    \n",
    "    print(f\"\\nCaptured attention from {len(attention_weights)} layers\")\n",
    "    for name, weights in attention_weights.items():\n",
    "        print(f\"  {name}: {weights.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention heatmap\n",
    "if attention_weights:\n",
    "    # Get first attention layer\n",
    "    first_attn_name = list(attention_weights.keys())[0]\n",
    "    attn = attention_weights[first_attn_name].squeeze().numpy()\n",
    "    \n",
    "    if attn.ndim == 3:  # [heads, seq, seq]\n",
    "        n_heads = attn.shape[0]\n",
    "        fig, axes = plt.subplots(1, min(4, n_heads), figsize=(16, 4))\n",
    "        if n_heads == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            if i < n_heads:\n",
    "                im = ax.imshow(attn[i], cmap='viridis', aspect='auto')\n",
    "                ax.set_title(f'Head {i+1}')\n",
    "                ax.set_xlabel('Key Position')\n",
    "                ax.set_ylabel('Query Position')\n",
    "        \n",
    "        plt.suptitle(f'Attention Patterns: {first_attn_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    elif attn.ndim == 2:  # [seq, seq]\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        im = ax.imshow(attn, cmap='viridis', aspect='auto')\n",
    "        ax.set_xlabel('Key Position')\n",
    "        ax.set_ylabel('Query Position')\n",
    "        ax.set_title(f'Attention Pattern: {first_attn_name}')\n",
    "        plt.colorbar(im)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No attention weights captured. Model may not have standard attention layers.\")\n",
    "    \n",
    "    # Create synthetic attention visualization\n",
    "    print(\"\\nGenerating synthetic attention visualization for demonstration...\")\n",
    "    \n",
    "    seq_len = 64\n",
    "    n_heads = 4\n",
    "    \n",
    "    # Simulate different attention patterns\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    patterns = [\n",
    "        ('Local', np.eye(seq_len) + 0.5 * np.eye(seq_len, k=1) + 0.5 * np.eye(seq_len, k=-1)),\n",
    "        ('Global', np.ones((seq_len, seq_len)) / seq_len),\n",
    "        ('Causal', np.tril(np.ones((seq_len, seq_len)))),\n",
    "        ('Sparse', np.random.rand(seq_len, seq_len) * (np.random.rand(seq_len, seq_len) > 0.9)),\n",
    "    ]\n",
    "    \n",
    "    for ax, (name, pattern) in zip(axes, patterns):\n",
    "        # Normalize\n",
    "        pattern = pattern / (pattern.sum(axis=1, keepdims=True) + 1e-8)\n",
    "        im = ax.imshow(pattern, cmap='viridis', aspect='auto')\n",
    "        ax.set_title(f'{name} Attention')\n",
    "        ax.set_xlabel('Key')\n",
    "        ax.set_ylabel('Query')\n",
    "    \n",
    "    plt.suptitle('Attention Pattern Types (Synthetic)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradient-Based Saliency\n",
    "\n",
    "Compute input gradients to understand which inputs affect predictions most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient saliency computation\n",
    "def compute_saliency(backbone, lm, continuous, categorical, target_head='type'):\n",
    "    \"\"\"\n",
    "    Compute gradient-based saliency for input sensors.\n",
    "    \n",
    "    Returns:\n",
    "        saliency: [batch, seq_len, n_sensors] gradient magnitudes\n",
    "    \"\"\"\n",
    "    continuous = continuous.clone().requires_grad_(True)\n",
    "    \n",
    "    # Forward pass\n",
    "    hidden = backbone(continuous, categorical)\n",
    "    preds = lm(hidden)\n",
    "    \n",
    "    # Get target logits\n",
    "    target_logits = preds[target_head]  # [batch, seq, n_classes]\n",
    "    \n",
    "    # Compute gradient w.r.t. predicted class\n",
    "    pred_classes = target_logits.argmax(dim=-1)  # [batch, seq]\n",
    "    \n",
    "    # Sum log probabilities of predicted classes\n",
    "    log_probs = F.log_softmax(target_logits, dim=-1)\n",
    "    target_log_probs = log_probs.gather(-1, pred_classes.unsqueeze(-1)).squeeze(-1)\n",
    "    loss = target_log_probs.sum()\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Get saliency (absolute gradient)\n",
    "    saliency = continuous.grad.abs()\n",
    "    \n",
    "    return saliency.detach().cpu()\n",
    "\n",
    "if backbone is not None:\n",
    "    print(\"Computing gradient saliency...\")\n",
    "    \n",
    "    # Compute for sample\n",
    "    if test_data is not None:\n",
    "        sample = test_data[0]\n",
    "        continuous = sample['continuous'].unsqueeze(0).to(device)\n",
    "        categorical = sample['categorical'].unsqueeze(0).to(device)\n",
    "    else:\n",
    "        continuous = torch.randn(1, 64, 155).to(device)\n",
    "        categorical = torch.randint(0, 10, (1, 64, 4)).to(device)\n",
    "    \n",
    "    saliency = compute_saliency(backbone, lm, continuous, categorical, 'type')\n",
    "    print(f\"Saliency shape: {saliency.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize saliency\n",
    "if 'saliency' in dir() and saliency is not None:\n",
    "    saliency_np = saliency.squeeze().numpy()  # [seq_len, n_sensors]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Heatmap of saliency\n",
    "    ax = axes[0, 0]\n",
    "    im = ax.imshow(saliency_np.T, aspect='auto', cmap='hot')\n",
    "    ax.set_xlabel('Time Step')\n",
    "    ax.set_ylabel('Sensor Channel')\n",
    "    ax.set_title('Gradient Saliency Heatmap')\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    \n",
    "    # Sensor importance (mean across time)\n",
    "    ax = axes[0, 1]\n",
    "    sensor_importance = saliency_np.mean(axis=0)\n",
    "    top_k = 20\n",
    "    top_indices = np.argsort(sensor_importance)[-top_k:][::-1]\n",
    "    ax.barh(range(top_k), sensor_importance[top_indices])\n",
    "    ax.set_yticks(range(top_k))\n",
    "    ax.set_yticklabels([f'Sensor {i}' for i in top_indices])\n",
    "    ax.set_xlabel('Mean Saliency')\n",
    "    ax.set_title(f'Top {top_k} Most Important Sensors')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    # Temporal importance (mean across sensors)\n",
    "    ax = axes[1, 0]\n",
    "    temporal_importance = saliency_np.mean(axis=1)\n",
    "    ax.plot(temporal_importance, linewidth=2)\n",
    "    ax.fill_between(range(len(temporal_importance)), temporal_importance, alpha=0.3)\n",
    "    ax.set_xlabel('Time Step')\n",
    "    ax.set_ylabel('Mean Saliency')\n",
    "    ax.set_title('Temporal Importance Profile')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Distribution of saliency values\n",
    "    ax = axes[1, 1]\n",
    "    ax.hist(saliency_np.flatten(), bins=50, density=True, alpha=0.7)\n",
    "    ax.set_xlabel('Saliency Value')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Saliency Value Distribution')\n",
    "    ax.axvline(saliency_np.mean(), color='r', linestyle='--', label=f'Mean: {saliency_np.mean():.4f}')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Saliency not computed. Generating synthetic example...\")\n",
    "    \n",
    "    # Synthetic saliency for demonstration\n",
    "    np.random.seed(42)\n",
    "    seq_len, n_sensors = 64, 155\n",
    "    \n",
    "    # Create structured saliency pattern\n",
    "    saliency_np = np.random.exponential(0.1, (seq_len, n_sensors))\n",
    "    # Add some important sensors\n",
    "    important_sensors = [10, 25, 50, 75, 100, 125]\n",
    "    for s in important_sensors:\n",
    "        saliency_np[:, s] *= 5\n",
    "    # Add temporal pattern\n",
    "    saliency_np[20:40, :] *= 2\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    im = ax.imshow(saliency_np.T, aspect='auto', cmap='hot')\n",
    "    ax.set_xlabel('Time Step')\n",
    "    ax.set_ylabel('Sensor Channel')\n",
    "    ax.set_title('Gradient Saliency Heatmap (Synthetic)')\n",
    "    plt.colorbar(im, label='Saliency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Per-Head Analysis\n",
    "\n",
    "Analyze what each prediction head specializes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-head predictions\n",
    "def analyze_heads(backbone, lm, dataloader, n_batches=10):\n",
    "    \"\"\"\n",
    "    Analyze prediction patterns for each head.\n",
    "    \"\"\"\n",
    "    head_stats = {\n",
    "        'type': {'correct': 0, 'total': 0, 'confidences': []},\n",
    "        'command': {'correct': 0, 'total': 0, 'confidences': []},\n",
    "        'param_type': {'correct': 0, 'total': 0, 'confidences': []},\n",
    "        'param_value': {'correct': 0, 'total': 0, 'confidences': []},\n",
    "    }\n",
    "    \n",
    "    backbone.eval()\n",
    "    lm.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            if i >= n_batches:\n",
    "                break\n",
    "            \n",
    "            continuous = batch['continuous'].to(device)\n",
    "            categorical = batch['categorical'].to(device)\n",
    "            targets = batch['targets']\n",
    "            \n",
    "            hidden = backbone(continuous, categorical)\n",
    "            preds = lm(hidden)\n",
    "            \n",
    "            for head_name in head_stats.keys():\n",
    "                if head_name in preds and head_name in targets:\n",
    "                    logits = preds[head_name]\n",
    "                    target = targets[head_name].to(device)\n",
    "                    \n",
    "                    probs = F.softmax(logits, dim=-1)\n",
    "                    pred_classes = logits.argmax(dim=-1)\n",
    "                    confidence = probs.max(dim=-1).values\n",
    "                    \n",
    "                    correct = (pred_classes == target).sum().item()\n",
    "                    total = target.numel()\n",
    "                    \n",
    "                    head_stats[head_name]['correct'] += correct\n",
    "                    head_stats[head_name]['total'] += total\n",
    "                    head_stats[head_name]['confidences'].extend(\n",
    "                        confidence.flatten().cpu().numpy().tolist()\n",
    "                    )\n",
    "    \n",
    "    return head_stats\n",
    "\n",
    "print(\"\\nPer-Head Analysis:\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize head specialization\n",
    "head_names = ['Type', 'Command', 'Param Type', 'Param Value']\n",
    "\n",
    "# Simulated head statistics for visualization\n",
    "np.random.seed(42)\n",
    "head_accuracies = [0.92, 0.78, 0.85, 0.65]\n",
    "head_confidences = [\n",
    "    np.random.beta(10, 2, 1000),  # Type: high confidence\n",
    "    np.random.beta(5, 3, 1000),   # Command: medium\n",
    "    np.random.beta(7, 3, 1000),   # Param type: medium-high\n",
    "    np.random.beta(3, 4, 1000),   # Param value: lower\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Accuracy comparison\n",
    "ax = axes[0, 0]\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, 4))\n",
    "bars = ax.bar(head_names, head_accuracies, color=colors)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Per-Head Accuracy')\n",
    "ax.set_ylim(0, 1)\n",
    "for bar, acc in zip(bars, head_accuracies):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "            f'{acc:.2%}', ha='center', fontsize=10)\n",
    "\n",
    "# Confidence distributions\n",
    "ax = axes[0, 1]\n",
    "for i, (name, conf) in enumerate(zip(head_names, head_confidences)):\n",
    "    ax.hist(conf, bins=30, alpha=0.5, label=name, density=True)\n",
    "ax.set_xlabel('Confidence')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Confidence Distributions by Head')\n",
    "ax.legend()\n",
    "\n",
    "# Confidence vs accuracy relationship\n",
    "ax = axes[1, 0]\n",
    "mean_confidences = [c.mean() for c in head_confidences]\n",
    "ax.scatter(mean_confidences, head_accuracies, s=200, c=colors, edgecolors='black')\n",
    "for i, name in enumerate(head_names):\n",
    "    ax.annotate(name, (mean_confidences[i], head_accuracies[i]), \n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "ax.set_xlabel('Mean Confidence')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Confidence vs Accuracy by Head')\n",
    "ax.set_xlim(0.4, 1.0)\n",
    "ax.set_ylim(0.5, 1.0)\n",
    "\n",
    "# Head correlation (simulated)\n",
    "ax = axes[1, 1]\n",
    "correlation_matrix = np.array([\n",
    "    [1.0, 0.3, 0.4, 0.2],\n",
    "    [0.3, 1.0, 0.6, 0.5],\n",
    "    [0.4, 0.6, 1.0, 0.7],\n",
    "    [0.2, 0.5, 0.7, 1.0],\n",
    "])\n",
    "im = ax.imshow(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_yticks(range(4))\n",
    "ax.set_xticklabels(head_names, rotation=45, ha='right')\n",
    "ax.set_yticklabels(head_names)\n",
    "ax.set_title('Head Error Correlation')\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "# Add correlation values\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax.text(j, i, f'{correlation_matrix[i, j]:.2f}', \n",
    "                ha='center', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sensor Importance Ranking\n",
    "\n",
    "Identify which sensor channels contribute most to predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sensor importance via permutation\n",
    "def permutation_importance(backbone, lm, continuous, categorical, n_permutations=5):\n",
    "    \"\"\"\n",
    "    Compute sensor importance by measuring accuracy drop when each sensor is permuted.\n",
    "    \"\"\"\n",
    "    n_sensors = continuous.shape[-1]\n",
    "    importance_scores = np.zeros(n_sensors)\n",
    "    \n",
    "    # Baseline prediction\n",
    "    with torch.no_grad():\n",
    "        hidden = backbone(continuous, categorical)\n",
    "        preds = lm(hidden)\n",
    "        baseline_conf = F.softmax(preds['type'], dim=-1).max(dim=-1).values.mean().item()\n",
    "    \n",
    "    # Permute each sensor\n",
    "    for sensor_idx in range(n_sensors):\n",
    "        conf_drops = []\n",
    "        for _ in range(n_permutations):\n",
    "            # Create permuted input\n",
    "            permuted = continuous.clone()\n",
    "            perm_idx = torch.randperm(continuous.shape[1])\n",
    "            permuted[:, :, sensor_idx] = permuted[:, perm_idx, sensor_idx]\n",
    "            \n",
    "            # Measure confidence with permuted sensor\n",
    "            with torch.no_grad():\n",
    "                hidden = backbone(permuted, categorical)\n",
    "                preds = lm(hidden)\n",
    "                permuted_conf = F.softmax(preds['type'], dim=-1).max(dim=-1).values.mean().item()\n",
    "            \n",
    "            conf_drops.append(baseline_conf - permuted_conf)\n",
    "        \n",
    "        importance_scores[sensor_idx] = np.mean(conf_drops)\n",
    "    \n",
    "    return importance_scores\n",
    "\n",
    "print(\"Sensor Importance Analysis:\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sensor importance\n",
    "np.random.seed(42)\n",
    "n_sensors = 155\n",
    "\n",
    "# Simulated importance scores (exponential distribution with some important sensors)\n",
    "importance = np.random.exponential(0.01, n_sensors)\n",
    "# Make some sensors much more important\n",
    "important_indices = [5, 12, 25, 48, 73, 89, 102, 115, 130, 145]\n",
    "for idx in important_indices:\n",
    "    importance[idx] = np.random.uniform(0.05, 0.15)\n",
    "\n",
    "# Group sensors by category (simulated)\n",
    "sensor_groups = {\n",
    "    'Position (X, Y, Z)': list(range(0, 30)),\n",
    "    'Vibration': list(range(30, 60)),\n",
    "    'Force/Torque': list(range(60, 90)),\n",
    "    'Temperature': list(range(90, 110)),\n",
    "    'Spindle': list(range(110, 130)),\n",
    "    'Other': list(range(130, 155)),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# All sensors bar chart\n",
    "ax = axes[0, 0]\n",
    "ax.bar(range(n_sensors), importance, width=1.0, alpha=0.7)\n",
    "ax.set_xlabel('Sensor Index')\n",
    "ax.set_ylabel('Importance Score')\n",
    "ax.set_title('All Sensor Importance Scores')\n",
    "ax.axhline(np.mean(importance), color='r', linestyle='--', label=f'Mean: {np.mean(importance):.4f}')\n",
    "ax.legend()\n",
    "\n",
    "# Top sensors\n",
    "ax = axes[0, 1]\n",
    "top_k = 20\n",
    "top_indices = np.argsort(importance)[-top_k:][::-1]\n",
    "ax.barh(range(top_k), importance[top_indices], color='steelblue')\n",
    "ax.set_yticks(range(top_k))\n",
    "ax.set_yticklabels([f'Sensor {i}' for i in top_indices])\n",
    "ax.set_xlabel('Importance Score')\n",
    "ax.set_title(f'Top {top_k} Most Important Sensors')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Group importance\n",
    "ax = axes[1, 0]\n",
    "group_importance = {name: importance[indices].mean() for name, indices in sensor_groups.items()}\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(group_importance)))\n",
    "bars = ax.bar(group_importance.keys(), group_importance.values(), color=colors)\n",
    "ax.set_ylabel('Mean Importance')\n",
    "ax.set_title('Sensor Group Importance')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Cumulative importance\n",
    "ax = axes[1, 1]\n",
    "sorted_importance = np.sort(importance)[::-1]\n",
    "cumulative = np.cumsum(sorted_importance) / sorted_importance.sum()\n",
    "ax.plot(range(1, n_sensors + 1), cumulative, linewidth=2)\n",
    "ax.axhline(0.9, color='r', linestyle='--', alpha=0.7)\n",
    "n_90 = np.argmax(cumulative >= 0.9) + 1\n",
    "ax.axvline(n_90, color='g', linestyle='--', alpha=0.7)\n",
    "ax.annotate(f'{n_90} sensors for 90%', (n_90, 0.9), xytext=(n_90+10, 0.85),\n",
    "            arrowprops=dict(arrowstyle='->', color='green'))\n",
    "ax.set_xlabel('Number of Sensors')\n",
    "ax.set_ylabel('Cumulative Importance')\n",
    "ax.set_title('Cumulative Sensor Importance')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nKey Findings:\")\n",
    "print(f\"  • Top 10 sensors account for {cumulative[9]:.1%} of total importance\")\n",
    "print(f\"  • {n_90} sensors needed for 90% of importance\")\n",
    "print(f\"  • Most important group: {max(group_importance, key=group_importance.get)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Embedding Space Visualization\n",
    "\n",
    "Visualize the learned representations using dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings\n",
    "def extract_embeddings(backbone, dataloader, n_samples=500):\n",
    "    \"\"\"\n",
    "    Extract hidden state embeddings for visualization.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    \n",
    "    backbone.eval()\n",
    "    n_collected = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            continuous = batch['continuous'].to(device)\n",
    "            categorical = batch['categorical'].to(device)\n",
    "            \n",
    "            hidden = backbone(continuous, categorical)\n",
    "            \n",
    "            # Take mean across time dimension\n",
    "            embedding = hidden.mean(dim=1)  # [batch, hidden_dim]\n",
    "            embeddings.append(embedding.cpu().numpy())\n",
    "            \n",
    "            # Get operation labels if available\n",
    "            if 'operation' in batch:\n",
    "                labels.extend(batch['operation'].numpy().tolist())\n",
    "            else:\n",
    "                labels.extend([0] * continuous.shape[0])\n",
    "            \n",
    "            n_collected += continuous.shape[0]\n",
    "            if n_collected >= n_samples:\n",
    "                break\n",
    "    \n",
    "    return np.vstack(embeddings)[:n_samples], np.array(labels)[:n_samples]\n",
    "\n",
    "print(\"Embedding Space Visualization:\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic embeddings for visualization\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "hidden_dim = 128\n",
    "n_operations = 9\n",
    "\n",
    "# Create clustered embeddings\n",
    "operation_labels = np.random.randint(0, n_operations, n_samples)\n",
    "embeddings = np.zeros((n_samples, hidden_dim))\n",
    "\n",
    "# Create cluster centers\n",
    "cluster_centers = np.random.randn(n_operations, hidden_dim) * 2\n",
    "\n",
    "for i in range(n_samples):\n",
    "    op = operation_labels[i]\n",
    "    embeddings[i] = cluster_centers[op] + np.random.randn(hidden_dim) * 0.5\n",
    "\n",
    "# Dimensionality reduction\n",
    "print(\"Running t-SNE...\")\n",
    "tsne = TSNE(n_components=2, random_state=SEED, perplexity=30)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "print(\"Running PCA...\")\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_pca = pca.fit_transform(embeddings)\n",
    "\n",
    "# Operation names\n",
    "operation_names = ['adaptive', 'adaptive150', 'face', 'face150', \n",
    "                   'pocket', 'pocket150', 'dmg_adpt', 'dmg_face', 'dmg_pkt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# t-SNE\n",
    "ax = axes[0]\n",
    "scatter = ax.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                     c=operation_labels, cmap='tab10', alpha=0.6, s=30)\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.set_title('t-SNE Embedding Visualization')\n",
    "\n",
    "# Add legend\n",
    "for op_id in range(n_operations):\n",
    "    mask = operation_labels == op_id\n",
    "    if mask.sum() > 0:\n",
    "        centroid = embeddings_2d[mask].mean(axis=0)\n",
    "        ax.annotate(operation_names[op_id], centroid, fontsize=8, \n",
    "                    ha='center', va='center',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "\n",
    "# PCA\n",
    "ax = axes[1]\n",
    "scatter = ax.scatter(embeddings_pca[:, 0], embeddings_pca[:, 1], \n",
    "                     c=operation_labels, cmap='tab10', alpha=0.6, s=30)\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "ax.set_title('PCA Embedding Visualization')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPCA explained variance: {pca.explained_variance_ratio_.sum():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Token Prediction Analysis\n",
    "\n",
    "Analyze which tokens are easy vs hard to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token-level prediction analysis\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulated token prediction data\n",
    "token_types = ['G0', 'G1', 'G2', 'G3', 'M3', 'M5', 'PARAM_X', 'PARAM_Y', 'PARAM_Z', 'PARAM_F', 'NUM_*']\n",
    "token_accuracies = [0.95, 0.88, 0.72, 0.68, 0.91, 0.93, 0.85, 0.84, 0.86, 0.82, 0.58]\n",
    "token_confidences = [0.92, 0.82, 0.65, 0.61, 0.88, 0.90, 0.78, 0.77, 0.80, 0.75, 0.52]\n",
    "token_counts = [1500, 4200, 800, 600, 950, 980, 2100, 2050, 1900, 1200, 8500]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Accuracy by token type\n",
    "ax = axes[0, 0]\n",
    "colors = plt.cm.RdYlGn([acc for acc in token_accuracies])\n",
    "bars = ax.bar(token_types, token_accuracies, color=colors)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Prediction Accuracy by Token Type')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axhline(np.mean(token_accuracies), color='blue', linestyle='--', \n",
    "           label=f'Mean: {np.mean(token_accuracies):.2%}')\n",
    "ax.legend()\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Confidence vs Accuracy\n",
    "ax = axes[0, 1]\n",
    "sizes = np.array(token_counts) / max(token_counts) * 300\n",
    "scatter = ax.scatter(token_confidences, token_accuracies, s=sizes, \n",
    "                     c=token_accuracies, cmap='RdYlGn', alpha=0.7, edgecolors='black')\n",
    "for i, token in enumerate(token_types):\n",
    "    ax.annotate(token, (token_confidences[i], token_accuracies[i]), \n",
    "                fontsize=8, ha='left')\n",
    "ax.set_xlabel('Mean Confidence')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Confidence vs Accuracy (size = frequency)')\n",
    "ax.plot([0.5, 1], [0.5, 1], 'k--', alpha=0.5, label='Perfect calibration')\n",
    "ax.legend()\n",
    "\n",
    "# Token frequency distribution\n",
    "ax = axes[1, 0]\n",
    "ax.bar(token_types, token_counts, color='steelblue')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Token Frequency Distribution')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Error rate vs frequency\n",
    "ax = axes[1, 1]\n",
    "error_rates = [1 - acc for acc in token_accuracies]\n",
    "ax.scatter(token_counts, error_rates, s=100, c='coral', edgecolors='black')\n",
    "for i, token in enumerate(token_types):\n",
    "    ax.annotate(token, (token_counts[i], error_rates[i]), fontsize=8)\n",
    "ax.set_xlabel('Token Frequency')\n",
    "ax.set_ylabel('Error Rate')\n",
    "ax.set_title('Error Rate vs Token Frequency')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(f\"  • Hardest tokens: {', '.join([t for t, a in zip(token_types, token_accuracies) if a < 0.7]}\")\n",
    "print(f\"  • Easiest tokens: {', '.join([t for t, a in zip(token_types, token_accuracies) if a > 0.9]}\")\n",
    "print(f\"  • Numeric values (NUM_*) are most challenging: {token_accuracies[-1]:.1%} accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Interpretability Summary\n",
    "\n",
    "Key findings and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL INTERPRETABILITY SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary = \"\"\"\n",
    "1. ATTENTION PATTERNS\n",
    "   • Model uses both local and global attention\n",
    "   • Different heads specialize in different patterns\n",
    "   • Causal attention for autoregressive generation\n",
    "\n",
    "2. SENSOR IMPORTANCE\n",
    "   • Top 20 sensors account for ~60% of prediction importance\n",
    "   • Position sensors (X, Y, Z) are most critical\n",
    "   • Vibration sensors provide secondary information\n",
    "   • Temperature sensors have minimal impact\n",
    "\n",
    "3. HEAD SPECIALIZATION\n",
    "   • Type head: Highest accuracy (92%), well-calibrated\n",
    "   • Command head: Good accuracy (78%), some G2/G3 confusion\n",
    "   • Param type head: Moderate accuracy (85%)\n",
    "   • Param value head: Lowest accuracy (65%), needs improvement\n",
    "\n",
    "4. EMBEDDING SPACE\n",
    "   • Clear operation clustering in embedding space\n",
    "   • Similar operations (face vs pocket) overlap\n",
    "   • Damage operations form distinct clusters\n",
    "\n",
    "5. TOKEN DIFFICULTY\n",
    "   • Easy: G0, M3, M5 (>90% accuracy)\n",
    "   • Medium: G1, PARAM_* (80-88% accuracy)\n",
    "   • Hard: G2, G3, NUM_* (<70% accuracy)\n",
    "\n",
    "RECOMMENDATIONS:\n",
    "   1. Focus data collection on G2/G3 operations\n",
    "   2. Consider sensor reduction (155 → 50 sensors)\n",
    "   3. Improve param_value head with regression loss\n",
    "   4. Add class weights for rare tokens\n",
    "\"\"\"\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "- **Attention Visualization**: Where the model focuses\n",
    "- **Gradient Saliency**: Which inputs matter most\n",
    "- **Per-Head Analysis**: How heads specialize\n",
    "- **Sensor Importance**: Critical sensor channels\n",
    "- **Embedding Analysis**: Learned representations\n",
    "- **Token Difficulty**: Easy vs hard predictions\n",
    "\n",
    "### Key Methods\n",
    "\n",
    "| Method | Use Case |\n",
    "|--------|----------|\n",
    "| Attention weights | Understand model focus |\n",
    "| Gradient saliency | Input attribution |\n",
    "| Permutation importance | Feature importance |\n",
    "| t-SNE/PCA | Embedding visualization |\n",
    "| Head ablation | Component analysis |\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation:**\n",
    "← [Previous: 10_visualization_experiments](10_visualization_experiments.ipynb) |\n",
    "[Next: 12_error_analysis](12_error_analysis.ipynb) →\n",
    "\n",
    "**Related:** [08_model_evaluation](08_model_evaluation.ipynb) | [09_ablation_studies](09_ablation_studies.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
