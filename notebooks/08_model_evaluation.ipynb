{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 - Model Evaluation\n\nComprehensive model evaluation and comparison.\n\n## Learning Objectives\n- Evaluate checkpoints on test set\n- Compare multiple models\n- Analyze failure cases\n- Generate evaluation reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\nimport sys\nfrom pathlib import Path\n\nproject_root = Path.cwd().parent\nsys.path.insert(0, str(project_root / 'src'))\n\nprint(f'Project root: {project_root}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single Checkpoint Evaluation\n\nEvaluate one checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command-line evaluation\nprint('To evaluate a checkpoint:')\nprint()\nprint('.venv/bin/python scripts/evaluate_checkpoint.py \\\\\\\\')\nprint('    --checkpoint outputs/best_from_sweep/checkpoint_best.pt \\\\\\\\')\nprint('    --test-data outputs/processed_current/test_sequences.npz \\\\\\\\')\nprint('    --vocab-path data/vocabulary.json \\\\\\\\')\nprint('    --output outputs/evaluation_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compare Multiple Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command-line comparison\nprint('To compare checkpoints:')\nprint()\nprint('.venv/bin/python scripts/compare_checkpoints.py \\\\\\\\')\nprint('    --checkpoints CP1.pt CP2.pt CP3.pt \\\\\\\\')\nprint('    --test-data outputs/processed_current/test_sequences.npz \\\\\\\\')\nprint('    --vocab-path data/vocabulary.json \\\\\\\\')\nprint('    --output outputs/checkpoint_comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation results\nimport json\nimport pandas as pd\n\nresults_path = project_root / 'outputs' / 'evaluation_results' / 'evaluation_results.json'\n\nif results_path.exists():\n    with open(results_path, 'r') as f:\n        results = json.load(f)\n    \n    metrics = results['metrics']\n    print('Evaluation Metrics:')\n    print(f'  Command Acc: {metrics[\"command_acc\"]:.4f}')\n    print(f'  Param Type Acc: {metrics[\"param_type_acc\"]:.4f}')\n    print(f'  Param Value Acc: {metrics[\"param_value_acc\"]:.4f}')\n    print(f'  Overall Acc: {metrics[\"overall_acc\"]:.4f}')\nelse:\n    print('No evaluation results found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n\nYou learned:\n- Evaluating single checkpoints\n- Comparing multiple models\n- Analyzing metrics\n- Generating reports\n\n## Congratulations!\n\nYou've completed all tutorial notebooks! You now have a complete understanding of the G-code fingerprinting project."
   ]
  }
 ],
 "metadata": {
  "kernelnel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}