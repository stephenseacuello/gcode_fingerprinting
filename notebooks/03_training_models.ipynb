{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 03 - Training Models\n",
    "\n",
    "**Learn how to train the Sensor Multi-Head Decoder for G-code generation.**\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the two-stage training architecture\n",
    "- Load preprocessed data and frozen encoder\n",
    "- Configure the SensorMultiHeadDecoder\n",
    "- Run training with curriculum learning and focal loss\n",
    "- Monitor per-head metrics during training\n",
    "- Save and evaluate checkpoints\n",
    "\n",
    "## Table of Contents\n",
    "1. [Architecture Overview](#1.-Architecture-Overview)\n",
    "2. [Environment Setup](#2.-Environment-Setup)\n",
    "3. [Load Data & Encoder](#3.-Load-Data-&-Encoder)\n",
    "4. [Model Configuration](#4.-Model-Configuration)\n",
    "5. [Training Configuration](#5.-Training-Configuration)\n",
    "6. [Training Loop](#6.-Training-Loop)\n",
    "7. [Results & Checkpoints](#7.-Results-&-Checkpoints)\n",
    "8. [Production Training](#8.-Production-Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Architecture Overview\n",
    "\n",
    "### Two-Stage Training\n",
    "\n",
    "The G-code fingerprinting model uses a **two-stage architecture**:\n",
    "\n",
    "| Stage | Component | Status | Purpose |\n",
    "|-------|-----------|--------|--------|\n",
    "| 1 | MM-DTAE-LSTM Encoder | **FROZEN** | Extract sensor embeddings + classify operations (100% accurate) |\n",
    "| 2 | SensorMultiHeadDecoder | **TRAINED** | Generate G-code tokens from embeddings |\n",
    "\n",
    "### Why Freeze the Encoder?\n",
    "\n",
    "- The encoder achieves ~100% operation classification accuracy\n",
    "- Freezing prevents catastrophic forgetting\n",
    "- Faster training (only decoder gradients)\n",
    "- Stable sensor embeddings for decoder learning\n",
    "\n",
    "### Multi-Head Outputs\n",
    "\n",
    "```\n",
    "SensorMultiHeadDecoder Outputs:\n",
    "├── type_logits      [B, L, 4]      → SPECIAL, COMMAND, PARAM, NUMERIC\n",
    "├── command_logits   [B, L, 6]      → G0, G1, G2, G3, G53, OTHER\n",
    "├── param_type_logits[B, L, 10]     → X, Y, Z, F, R, S, I, J, K, OTHER\n",
    "├── sign_logits      [B, L, 3]      → Positive, Negative, Zero\n",
    "├── digit_logits     [B, L, 6, 10]  → 6 digits (2 int + 4 decimal)\n",
    "└── aux_value        [B, L, 1]      → Auxiliary regression target\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Load Data & Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data splits\n",
    "split_dir = project_root / 'outputs' / 'stratified_splits_v2'\n",
    "\n",
    "if not split_dir.exists():\n",
    "    # Try alternative paths\n",
    "    alt_dirs = [\n",
    "        project_root / 'outputs' / 'multilabel_stratified_splits',\n",
    "        project_root / 'outputs' / 'sample_stratified_splits',\n",
    "    ]\n",
    "    for d in alt_dirs:\n",
    "        if d.exists():\n",
    "            split_dir = d\n",
    "            break\n",
    "\n",
    "print(f\"Split directory: {split_dir}\")\n",
    "\n",
    "# Load training data\n",
    "train_data = np.load(split_dir / 'train_sequences.npz', allow_pickle=True)\n",
    "val_data = np.load(split_dir / 'val_sequences.npz', allow_pickle=True)\n",
    "\n",
    "print(f\"\\nData loaded:\")\n",
    "print(f\"  Train samples: {len(train_data['continuous'])}\")\n",
    "print(f\"  Val samples:   {len(val_data['continuous'])}\")\n",
    "\n",
    "print(f\"\\nData shapes:\")\n",
    "for key in ['continuous', 'categorical', 'tokens', 'operation_type']:\n",
    "    if key in train_data:\n",
    "        print(f\"  {key}: {train_data[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets\n",
    "class SensorTokenDataset(Dataset):\n",
    "    \"\"\"Dataset for sensor-to-token training.\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.continuous = torch.FloatTensor(data['continuous'])\n",
    "        self.categorical = torch.LongTensor(data['categorical'])\n",
    "        self.tokens = torch.LongTensor(data['tokens'])\n",
    "        self.operation_type = torch.LongTensor(data['operation_type'])\n",
    "        \n",
    "        # Optional: raw values for auxiliary regression\n",
    "        if 'param_value_raw' in data:\n",
    "            self.param_value_raw = torch.FloatTensor(data['param_value_raw'])\n",
    "        else:\n",
    "            self.param_value_raw = torch.zeros_like(self.tokens, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.continuous)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'continuous': self.continuous[idx],\n",
    "            'categorical': self.categorical[idx],\n",
    "            'tokens': self.tokens[idx],\n",
    "            'operation_type': self.operation_type[idx],\n",
    "            'param_value_raw': self.param_value_raw[idx],\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SensorTokenDataset(train_data)\n",
    "val_dataset = SensorTokenDataset(val_data)\n",
    "\n",
    "# Create dataloaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Dataloaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches:   {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load frozen encoder\n",
    "encoder_path = project_root / 'outputs' / 'mm_dtae_lstm_v2' / 'best_model.pt'\n",
    "\n",
    "if encoder_path.exists():\n",
    "    print(f\"Loading encoder from: {encoder_path}\")\n",
    "    encoder_checkpoint = torch.load(encoder_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    print(f\"\\nEncoder checkpoint keys: {list(encoder_checkpoint.keys())}\")\n",
    "    \n",
    "    # The encoder embeddings are pre-computed in the split data\n",
    "    # For this notebook, we'll use the sensor data directly\n",
    "    print(f\"\\n✓ Encoder checkpoint loaded\")\n",
    "else:\n",
    "    print(f\"⚠ Encoder not found at: {encoder_path}\")\n",
    "    print(f\"  Will use raw sensor data instead of embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Configuration\n",
    "\n",
    "### SensorMultiHeadDecoder Configuration\n",
    "\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| d_model | 192 | Hidden dimension |\n",
    "| n_heads | 8 | Attention heads |\n",
    "| n_layers | 4 | Transformer layers |\n",
    "| sensor_dim | 128 | Encoder output dimension |\n",
    "| n_operations | 9 | Operation type classes |\n",
    "| n_types | 4 | Token type classes |\n",
    "| n_commands | 6 | Command classes |\n",
    "| n_param_types | 10 | Parameter type classes |\n",
    "| dropout | 0.3 | Dropout rate |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "model_config = {\n",
    "    'vocab_size': 668,  # Total vocabulary size\n",
    "    'd_model': 192,\n",
    "    'n_heads': 8,\n",
    "    'n_layers': 4,\n",
    "    'sensor_dim': 128,\n",
    "    'n_operations': 9,\n",
    "    'n_types': 4,\n",
    "    'n_commands': 6,\n",
    "    'n_param_types': 10,\n",
    "    'max_seq_len': 32,\n",
    "    'dropout': 0.3,\n",
    "    'embed_dropout': 0.1,\n",
    "}\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "print(\"=\"*50)\n",
    "for k, v in model_config.items():\n",
    "    print(f\"  {k:20s}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "from miracle.model.sensor_multihead_decoder import SensorMultiHeadDecoder\n",
    "\n",
    "model = SensorMultiHeadDecoder(\n",
    "    vocab_size=model_config['vocab_size'],\n",
    "    d_model=model_config['d_model'],\n",
    "    n_heads=model_config['n_heads'],\n",
    "    n_layers=model_config['n_layers'],\n",
    "    sensor_dim=model_config['sensor_dim'],\n",
    "    n_operations=model_config['n_operations'],\n",
    "    n_types=model_config['n_types'],\n",
    "    n_commands=model_config['n_commands'],\n",
    "    n_param_types=model_config['n_param_types'],\n",
    "    max_seq_len=model_config['max_seq_len'],\n",
    "    dropout=model_config['dropout'],\n",
    "    embed_dropout=model_config['embed_dropout'],\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "param_counts = model.count_parameters()\n",
    "\n",
    "print(\"\\nModel Parameter Counts:\")\n",
    "print(\"-\" * 50)\n",
    "for name, count in param_counts.items():\n",
    "    print(f\"  {name:25s}: {count:>10,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Training Configuration\n",
    "\n",
    "### Key Training Features\n",
    "\n",
    "1. **Focal Loss**: Handles class imbalance (gamma=3.0)\n",
    "2. **Label Smoothing**: Improves generalization (0.1)\n",
    "3. **Curriculum Learning**: Structure → Coarse Digits → Full Precision\n",
    "4. **Cosine LR Schedule**: With warmup epochs\n",
    "5. **Gradient Clipping**: Prevents exploding gradients (1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "train_config = {\n",
    "    # Training\n",
    "    'max_epochs': 5,  # Short demo (use 150 for production)\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'patience': 30,\n",
    "    \n",
    "    # Optimizer\n",
    "    'learning_rate': 2e-4,\n",
    "    'weight_decay': 0.05,\n",
    "    'grad_clip': 1.0,\n",
    "    \n",
    "    # LR Schedule\n",
    "    'warmup_epochs': 1,  # Short demo\n",
    "    \n",
    "    # Loss weights\n",
    "    'type_weight': 1.0,\n",
    "    'command_weight': 2.5,\n",
    "    'param_type_weight': 1.5,\n",
    "    'digit_weight': 1.0,\n",
    "    \n",
    "    # Focal loss\n",
    "    'use_focal_loss': True,\n",
    "    'focal_gamma': 3.0,\n",
    "    \n",
    "    # Label smoothing\n",
    "    'label_smoothing': 0.1,\n",
    "    \n",
    "    # Curriculum (disabled for short demo)\n",
    "    'use_curriculum': False,\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\"*50)\n",
    "for k, v in train_config.items():\n",
    "    print(f\"  {k:25s}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=train_config['learning_rate'],\n",
    "    weight_decay=train_config['weight_decay'],\n",
    "    betas=(0.9, 0.999),\n",
    ")\n",
    "\n",
    "# Learning rate scheduler (cosine with warmup)\n",
    "def get_lr_lambda(epoch, warmup_epochs=1, total_epochs=5):\n",
    "    if epoch < warmup_epochs:\n",
    "        return (epoch + 1) / warmup_epochs\n",
    "    else:\n",
    "        progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)\n",
    "        return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(\n",
    "    optimizer, \n",
    "    lr_lambda=lambda e: get_lr_lambda(e, train_config['warmup_epochs'], train_config['max_epochs'])\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: AdamW (lr={train_config['learning_rate']}, wd={train_config['weight_decay']})\")\n",
    "print(f\"Scheduler: Cosine with {train_config['warmup_epochs']} warmup epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "from miracle.training.losses import FocalLoss\n",
    "\n",
    "# Focal loss for classification heads\n",
    "if train_config['use_focal_loss']:\n",
    "    type_criterion = FocalLoss(gamma=train_config['focal_gamma'], label_smoothing=train_config['label_smoothing'])\n",
    "    command_criterion = FocalLoss(gamma=train_config['focal_gamma'], label_smoothing=train_config['label_smoothing'])\n",
    "    param_type_criterion = FocalLoss(gamma=train_config['focal_gamma'], label_smoothing=train_config['label_smoothing'])\n",
    "    digit_criterion = FocalLoss(gamma=train_config['focal_gamma'], label_smoothing=train_config['label_smoothing'])\n",
    "else:\n",
    "    type_criterion = nn.CrossEntropyLoss(label_smoothing=train_config['label_smoothing'])\n",
    "    command_criterion = nn.CrossEntropyLoss(label_smoothing=train_config['label_smoothing'])\n",
    "    param_type_criterion = nn.CrossEntropyLoss(label_smoothing=train_config['label_smoothing'])\n",
    "    digit_criterion = nn.CrossEntropyLoss(label_smoothing=train_config['label_smoothing'])\n",
    "\n",
    "print(f\"Loss: {'Focal Loss (gamma=' + str(train_config['focal_gamma']) + ')' if train_config['use_focal_loss'] else 'Cross Entropy'}\")\n",
    "print(f\"Label smoothing: {train_config['label_smoothing']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions\n",
    "def compute_loss(outputs, batch, train_config):\n",
    "    \"\"\"Compute multi-head loss.\"\"\"\n",
    "    tokens = batch['tokens']\n",
    "    B, L = tokens.shape\n",
    "    \n",
    "    # For this demo, we use the legacy token prediction\n",
    "    # Production code uses full multi-head decomposition\n",
    "    legacy_logits = outputs['legacy_logits']  # [B, L, vocab_size]\n",
    "    \n",
    "    # Compute cross-entropy loss\n",
    "    legacy_logits_flat = legacy_logits.view(-1, legacy_logits.size(-1))\n",
    "    tokens_flat = tokens.view(-1)\n",
    "    \n",
    "    # Ignore padding (assuming PAD=0)\n",
    "    loss = F.cross_entropy(legacy_logits_flat, tokens_flat, ignore_index=0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def compute_accuracy(outputs, batch):\n",
    "    \"\"\"Compute token accuracy.\"\"\"\n",
    "    tokens = batch['tokens']\n",
    "    legacy_logits = outputs['legacy_logits']\n",
    "    \n",
    "    # Get predictions\n",
    "    preds = legacy_logits.argmax(dim=-1)  # [B, L]\n",
    "    \n",
    "    # Mask padding\n",
    "    mask = tokens != 0\n",
    "    \n",
    "    correct = ((preds == tokens) & mask).sum().item()\n",
    "    total = mask.sum().item()\n",
    "    \n",
    "    return correct / max(total, 1)\n",
    "\n",
    "print(\"✓ Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, train_config, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    n_batches = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training', leave=False)\n",
    "    for batch in pbar:\n",
    "        # Move to device\n",
    "        continuous = batch['continuous'].to(device)\n",
    "        tokens = batch['tokens'].to(device)\n",
    "        operation_type = batch['operation_type'].to(device)\n",
    "        \n",
    "        # For demo: use continuous as sensor embeddings (normally from encoder)\n",
    "        # Average pool to get [B, sensor_dim]\n",
    "        sensor_emb = continuous.mean(dim=1, keepdim=True).expand(-1, continuous.size(1), -1)\n",
    "        sensor_emb = sensor_emb[:, :, :128]  # Take first 128 dims\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(tokens, sensor_emb, operation_type)\n",
    "        \n",
    "        # Compute loss\n",
    "        batch_dict = {'tokens': tokens}\n",
    "        loss = compute_loss(outputs, batch_dict, train_config)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), train_config['grad_clip'])\n",
    "        \n",
    "        # Update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Metrics\n",
    "        acc = compute_accuracy(outputs, batch_dict)\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "        n_batches += 1\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{acc:.2%}'})\n",
    "    \n",
    "    return total_loss / n_batches, total_acc / n_batches\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, val_loader, train_config, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    n_batches = 0\n",
    "    \n",
    "    for batch in tqdm(val_loader, desc='Validating', leave=False):\n",
    "        continuous = batch['continuous'].to(device)\n",
    "        tokens = batch['tokens'].to(device)\n",
    "        operation_type = batch['operation_type'].to(device)\n",
    "        \n",
    "        # Sensor embeddings (same as training)\n",
    "        sensor_emb = continuous.mean(dim=1, keepdim=True).expand(-1, continuous.size(1), -1)\n",
    "        sensor_emb = sensor_emb[:, :, :128]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(tokens, sensor_emb, operation_type)\n",
    "        \n",
    "        # Metrics\n",
    "        batch_dict = {'tokens': tokens}\n",
    "        loss = compute_loss(outputs, batch_dict, train_config)\n",
    "        acc = compute_accuracy(outputs, batch_dict)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "        n_batches += 1\n",
    "    \n",
    "    return total_loss / n_batches, total_acc / n_batches\n",
    "\n",
    "print(\"✓ Train/validate functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training loop\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_acc': [], 'val_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "print(f\"Starting training for {train_config['max_epochs']} epochs...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(train_config['max_epochs']):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, train_config, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate(model, val_loader, train_config, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Check best\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{train_config['max_epochs']} ({epoch_time:.1f}s)\")\n",
    "    print(f\"  Train: loss={train_loss:.4f}, acc={train_acc:.2%}\")\n",
    "    print(f\"  Val:   loss={val_loss:.4f}, acc={val_acc:.2%}\")\n",
    "    print(f\"  LR:    {current_lr:.2e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Training complete!\")\n",
    "print(f\"Best val accuracy: {best_val_acc:.2%} (epoch {best_epoch+1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss\n",
    "ax1 = axes[0]\n",
    "ax1.plot(epochs, history['train_loss'], 'b-o', label='Train', linewidth=2, markersize=6)\n",
    "ax1.plot(epochs, history['val_loss'], 'r-s', label='Val', linewidth=2, markersize=6)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "ax2 = axes[1]\n",
    "ax2.plot(epochs, [a*100 for a in history['train_acc']], 'b-o', label='Train', linewidth=2, markersize=6)\n",
    "ax2.plot(epochs, [a*100 for a in history['val_acc']], 'r-s', label='Val', linewidth=2, markersize=6)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Token Accuracy', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "ax3 = axes[2]\n",
    "ax3.plot(epochs, history['lr'], 'g-o', linewidth=2, markersize=6)\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Learning Rate')\n",
    "ax3.set_title('LR Schedule', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Results & Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "checkpoint_dir = project_root / 'outputs' / 'notebook_training'\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "checkpoint = {\n",
    "    'epoch': train_config['max_epochs'],\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'config': {**model_config, **train_config},\n",
    "    'history': history,\n",
    "    'best_val_acc': best_val_acc,\n",
    "}\n",
    "\n",
    "checkpoint_path = checkpoint_dir / 'checkpoint_demo.pt'\n",
    "torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "print(f\"✓ Checkpoint saved to: {checkpoint_path}\")\n",
    "print(f\"  Size: {checkpoint_path.stat().st_size / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect production checkpoint\n",
    "prod_checkpoint_path = project_root / 'outputs' / 'sensor_multihead_v3' / 'best_model.pt'\n",
    "\n",
    "if prod_checkpoint_path.exists():\n",
    "    prod_checkpoint = torch.load(prod_checkpoint_path, map_location='cpu', weights_only=False)\n",
    "    \n",
    "    print(\"Production Checkpoint:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"  Path: {prod_checkpoint_path}\")\n",
    "    print(f\"  Size: {prod_checkpoint_path.stat().st_size / (1024*1024):.1f} MB\")\n",
    "    \n",
    "    print(f\"\\nCheckpoint contents:\")\n",
    "    for key in prod_checkpoint.keys():\n",
    "        if 'state_dict' in key:\n",
    "            print(f\"  {key}: {len(prod_checkpoint[key])} parameters\")\n",
    "        elif isinstance(prod_checkpoint[key], dict):\n",
    "            print(f\"  {key}: dict\")\n",
    "        else:\n",
    "            print(f\"  {key}: {type(prod_checkpoint[key]).__name__}\")\n",
    "else:\n",
    "    print(f\"Production checkpoint not found at: {prod_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Production Training\n",
    "\n",
    "For production training, use the command-line script with full features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production training commands\n",
    "print(\"=\"*70)\n",
    "print(\"PRODUCTION TRAINING COMMANDS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. Full Training (Recommended):\")\n",
    "print(\"-\"*50)\n",
    "cmd1 = \"\"\"\n",
    "PYTORCH_ENABLE_MPS_FALLBACK=1 PYTHONPATH=src .venv/bin/python \\\n",
    "    scripts/train_sensor_multihead.py \\\n",
    "    --split-dir outputs/stratified_splits_v2 \\\n",
    "    --vocab-path data/vocabulary_4digit_hybrid.json \\\n",
    "    --encoder-path outputs/mm_dtae_lstm_v2/best_model.pt \\\n",
    "    --output-dir outputs/sensor_multihead_v4 \\\n",
    "    --d-model 192 \\\n",
    "    --n-heads 8 \\\n",
    "    --n-layers 4 \\\n",
    "    --max-epochs 150 \\\n",
    "    --batch-size 32 \\\n",
    "    --learning-rate 2e-4 \\\n",
    "    --use-focal-loss \\\n",
    "    --curriculum \\\n",
    "    --use-wandb\n",
    "\"\"\"\n",
    "print(cmd1)\n",
    "\n",
    "print(\"\\n2. Quick Training (Testing):\")\n",
    "print(\"-\"*50)\n",
    "cmd2 = \"\"\"\n",
    "PYTORCH_ENABLE_MPS_FALLBACK=1 PYTHONPATH=src .venv/bin/python \\\n",
    "    scripts/train_sensor_multihead.py \\\n",
    "    --split-dir outputs/stratified_splits_v2 \\\n",
    "    --vocab-path data/vocabulary_4digit_hybrid.json \\\n",
    "    --encoder-path outputs/mm_dtae_lstm_v2/best_model.pt \\\n",
    "    --output-dir outputs/quick_test \\\n",
    "    --max-epochs 10 \\\n",
    "    --batch-size 16\n",
    "\"\"\"\n",
    "print(cmd2)\n",
    "\n",
    "print(\"\\n3. Resume Training:\")\n",
    "print(\"-\"*50)\n",
    "cmd3 = \"\"\"\n",
    "PYTHONPATH=src .venv/bin/python scripts/train_sensor_multihead.py \\\n",
    "    --split-dir outputs/stratified_splits_v2 \\\n",
    "    --vocab-path data/vocabulary_4digit_hybrid.json \\\n",
    "    --encoder-path outputs/mm_dtae_lstm_v2/best_model.pt \\\n",
    "    --output-dir outputs/sensor_multihead_v3 \\\n",
    "    --resume outputs/sensor_multihead_v3/best_model.pt \\\n",
    "    --max-epochs 200\n",
    "\"\"\"\n",
    "print(cmd3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **Two-Stage Architecture**: Frozen encoder + trainable decoder\n",
    "2. **Data Loading**: NPZ files with sensor data and tokens\n",
    "3. **Model Configuration**: SensorMultiHeadDecoder with 192 hidden dim, 8 heads, 4 layers\n",
    "4. **Training Features**: Focal loss, curriculum learning, cosine LR schedule\n",
    "5. **Monitoring**: Per-epoch loss and accuracy tracking\n",
    "6. **Checkpoints**: Saving and loading model state\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Feature | Setting | Purpose |\n",
    "|---------|---------|--------|\n",
    "| Focal Loss | gamma=3.0 | Handle class imbalance |\n",
    "| Label Smoothing | 0.1 | Improve generalization |\n",
    "| Curriculum | 3 phases | Structure → Digits → Full |\n",
    "| Command Weight | 2.5x | Prioritize command accuracy |\n",
    "| Dropout | 0.3 | Regularization |\n",
    "\n",
    "### Production Results (sensor_multihead_v3)\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Val Token Accuracy | ~90% |\n",
    "| Test Token Accuracy | ~90% |\n",
    "| Training Time | ~2-3 hours (150 epochs) |\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation:**\n",
    "← [Previous: 02_data_preprocessing](02_data_preprocessing.ipynb) |\n",
    "[Next: 04_inference_prediction](04_inference_prediction.ipynb) →\n",
    "\n",
    "**Related:** [07_hyperparameter_sweeps](07_hyperparameter_sweeps.ipynb) | [08_model_evaluation](08_model_evaluation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
